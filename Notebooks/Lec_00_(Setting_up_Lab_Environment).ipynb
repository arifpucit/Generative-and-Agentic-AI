{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a41c76e0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "---   \n",
    " <img align=\"left\" width=\"75\" height=\"75\"  src=\"https://upload.wikimedia.org/wikipedia/en/c/c8/University_of_the_Punjab_logo.png\"> \n",
    "\n",
    "<h1 align=\"center\">Department of Data Science</h1>\n",
    "<h1 align=\"center\">Course: Generative and Agentic AI</h1>\n",
    "\n",
    "---\n",
    "<h3><div align=\"right\">Instructor: Muhammad Arif Butt, Ph.D.</div></h3>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595a85d8-21c0-4847-8cf1-bb06f225822a",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Lec-00: Setting Up Your Lab Environment</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef15071",
   "metadata": {},
   "source": [
    "# Learning agenda of this notebook\n",
    "1. Building up your Environment\n",
    "    - Python Version Recommendations\n",
    "    - Option 1 (Use `pip` to create Virtual Environment and install packages using `requirements.txt`)\n",
    "    - Option 2 (Use `conda` to create Virtual Environment and install packages using `environment.yml`)\n",
    "    - Option 3 (Use `uv` to create Virtual Environment and install packages using `requirements.txt`)\n",
    "2. Check the H/W Specification of your Laptop\n",
    "3. Perform a Health Check of your environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb4cf04-11ca-4f43-83c4-6fd30a17323e",
   "metadata": {},
   "source": [
    "# <span style='background :lightgreen' >1. Building up your GenAI Environment</span>\n",
    "\n",
    "<h2 align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">I highly recommend installing Python packages in a separate virtual environment to avoid modifying system-wide packages that your OS may depend on</h2>\n",
    "\n",
    "## Check your Python Version\n",
    "- Open a new Terminal and run the command `python --version` to find out which python you're on. To download Python visit: https://www.python.org/downloads/\n",
    "- Ideally you'd be using a version of Python 3.11, even if you are using Python 3.12 I think it OK. However as of Feb 2025, Python 3.13 does not work as several Data Science dependencies are not yet ready for Python 3.13.\n",
    "- Python Version Guidelines (December 2025):\n",
    "    - Python 3.11: Most stable for GenAI/ML work, highly recommended\n",
    "    - Python 3.12: Fully supported by most major libraries, safe to use\n",
    "    - Python 3.13: Now supported by major frameworks as of December 2025\n",
    "    - PyTorch 2.6+ has official Python 3.13 support (released early 2025)\n",
    "    - TensorFlow support varies - check current compatibility before using\n",
    "    - NumPy, Pandas, and scikit-learn now support 3.13\n",
    "- **Recommendation:** Use Python 3.11 or 3.12 for production work; 3.13 for experimentation with latest features\n",
    "\n",
    "## Option 1 (Use `pip` - Pythonâ€™s built-in package manager)\n",
    "- **`pip`** installs and manages Python packages from the Python Package Index (PyPI).\n",
    "- It works directly with venv to create lightweight virtual environments.\n",
    "- Itâ€™s simple, fast, and the most universally supported option for pure Python workflows.\n",
    "- Download the **`requirements.txt`** file from https://github.com/arifpucit/Generative-and-Agentic-AI/tree/main/Notebooks\n",
    "- On your Windows, Linux or Mac machine, open up a terminal and create a project root directory where all your projects and sample codes will reside, lets name it llms\n",
    "```\n",
    "mkdir llms                            # Create a new directory (root project directory)\n",
    "cd llms                               # Navigate into the directory\n",
    "python -m pip install --upgrade pip   # Install and upgrade pip\n",
    "python -m venv llms                   # Create a virtual environment named 'llms'\n",
    "source llms/bin/activate              # Activate on macOS/Linux - you'll see (llms) in prompt\n",
    ".\\llms\\Scripts\\activate               # Activate on Windows - you'll see (llms) in prompt\n",
    "pip install -r requirements.txt       # Install all required packages (20-30 min)\n",
    "jupyter lab                           # Start Jupyter Lab\n",
    "deactivate                            # Deactivate when done\n",
    "```\n",
    "\n",
    "## Option 2 (Use `conda` - environment + package manager for Python, R, C/C++ libs, etc.)\n",
    "- **`conda`** manages both environments and packages, including non-Python dependencies like NumPy MKL, CUDA, and system libraries.\n",
    "- It can create isolated environments that bundle Python versions and binary dependencies together.\n",
    "- Itâ€™s popular in data science because it handles heavy scientific packages reliably.\n",
    "- Download the **`environment.yml`** file from https://github.com/arifpucit/Generative-and-Agentic-AI/tree/main/Notebooks\n",
    "- Download and install Anaconda: Visit: https://docs.anaconda.com/anaconda/install/ by choosing appropriate installer for Mac, Linux, or Windows\n",
    "```bash\n",
    "mkdir llms                            # Create a new directory (root project directory)\n",
    "cd llms                               # Navigate into the directory\n",
    "conda env create -f environment.yml   # Create environment from YAML file (20-30 min)\n",
    "conda activate llms                   # Activate environment - you'll see (llms) in prompt\n",
    "jupyter lab                           # Start Jupyter Lab\n",
    "conda deactivate                      # Deactivate when done\n",
    "```\n",
    "\n",
    "\n",
    "## Option 3 (Use `uv` - a modern, ultra-fast Python package and environment tool by Astral\n",
    "- **`uv`** is a next-generation Python package manager written in Rust that replaces `pip`, `venv`, `poetry`, `pyenv`, and `virtualenv` with a single, blazingly fast tool.\n",
    "- It is designed for speedâ€”environment creation and package installation are significantly faster than pip or conda.\n",
    "- Download the **`requirements.txt`** file from https://github.com/arifpucit/Generative-and-Agentic-AI/tree/main/Notebooks\n",
    "```bash\n",
    "pip install uv                        # Install uv using pip\n",
    "mkdir llms                            # Create a new directory (root project directory)\n",
    "cd llms                               # Navigate into the directory\n",
    "uv init .                             # Initialize project (creates pyproject.toml, etc.)\n",
    "uv add -r requirements.txt            # Import all dependencies from requirements.txt\n",
    "uv sync                               # Sync environment with dependencies\n",
    "uv shell                              # Activate the uv environment - you'll see (llms) in prompt\n",
    "jupyter lab                           # Start Jupyter Lab\n",
    "exit                                  # Exit the uv shell when done\n",
    "```\n",
    "\n",
    "#### Start Jupyter Lab:\n",
    "- Finally, inside the project root directory, after you have activated the environment, start the Jupyter lab by giving the command: `jupyter lab`, which will open up Jupyter Lab inside your default browser.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "> **Remember, in future, whenever, you are going to start working, you must go to your project root directory, activate the virtual environment you have created and then start jupyter lab**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b120fe-6db4-4609-84ec-9af564713c72",
   "metadata": {},
   "source": [
    "### requirements.txt (for `pip` and `uv`)\n",
    "```python\n",
    "numpy==2.2.6\n",
    "pandas==2.3.0\n",
    "scipy==1.13.1\n",
    "matplotlib==3.10.3\n",
    "plotly==6.1.2\n",
    "torch==2.7.1\n",
    "transformers==4.52.4\n",
    "sentence-transformers==5.1.1\n",
    "datasets==2.14.4\n",
    "accelerate==1.8.1\n",
    "scikit-learn==1.7.0\n",
    "bitsandbytes==0.42.0\n",
    "langchain==0.3.25\n",
    "langchain-core==0.3.69\n",
    "langchain-community==0.3.24\n",
    "langsmith==0.3.45\n",
    "langgraph\n",
    "chromadb==1.0.12\n",
    "pinecone-client==7.3.0\n",
    "weaviate-client==4.16.9\n",
    "qdrant-client\n",
    "psycopg2==2.9.10\n",
    "PyMySQL==1.4.6\n",
    "SQLAlchemy==2.0.41\n",
    "redis==6.4.0\n",
    "pymongo==4.13.2\n",
    "neo4j==5.28.2\n",
    "cassandra-driver==3.29.2\n",
    "openai==1.85.0\n",
    "anthropic==0.58.2\n",
    "google-generativeai==0.8.5\n",
    "modal==1.0.4\n",
    "requests==2.32.3\n",
    "beautifulsoup4==4.13.4\n",
    "feedparser==6.0.11\n",
    "pyarrow==20.0.0\n",
    "pydub\n",
    "sentencepiece==0.2.0\n",
    "jupyterlab==4.4.3\n",
    "gradio==5.34.2\n",
    "ipywidgets==8.1.7\n",
    "psutil==7.0.0\n",
    "python-dotenv\n",
    "twilio==9.8.0\n",
    "speedtest-cli==2.1.3\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266071c8-61c4-4f10-9026-cf6f0598ccaf",
   "metadata": {},
   "source": [
    "### environment.yml (for `conda`)\n",
    "```python\n",
    "name: llms\n",
    "channels:\n",
    "  - defaults\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.11\n",
    "  - pip\n",
    "  - numpy=2.2.6\n",
    "  - pandas=2.3.0\n",
    "  - scipy=1.13.1\n",
    "  - matplotlib=3.10.3\n",
    "  - plotly=6.1.2\n",
    "  - scikit-learn=1.7.0\n",
    "  - sqlalchemy=2.0.41\n",
    "  - psycopg2=2.9.10\n",
    "  - pymysql=1.4.6\n",
    "  - redis-py=6.4.0\n",
    "  - pymongo=4.13.2\n",
    "  - pyarrow=20.0.0\n",
    "  - ipywidgets=8.1.7\n",
    "  - jupyterlab=4.4.3\n",
    "  - pip:\n",
    "      - torch==2.7.1\n",
    "      - transformers==4.52.4\n",
    "      - sentence-transformers==5.1.1\n",
    "      - datasets==2.14.4\n",
    "      - accelerate==1.8.1\n",
    "      - bitsandbytes==0.42.0\n",
    "      - langchain==0.3.25\n",
    "      - langchain-core==0.3.69\n",
    "      - langchain-community==0.3.24\n",
    "      - langsmith==0.3.45\n",
    "      - langgraph\n",
    "      - chromadb==1.0.12\n",
    "      - pinecone-client==7.3.0\n",
    "      - weaviate-client==4.16.9\n",
    "      - qdrant-client\n",
    "      - neo4j==5.28.2\n",
    "      - cassandra-driver==3.29.2\n",
    "      - openai==1.85.0\n",
    "      - anthropic==0.58.2\n",
    "      - google-generativeai==0.8.5\n",
    "      - modal==1.0.4\n",
    "      - requests==2.32.3\n",
    "      - beautifulsoup4==4.13.4\n",
    "      - feedparser==6.0.11\n",
    "      - pydub\n",
    "      - sentencepiece==0.2.0\n",
    "      - gradio==5.34.2\n",
    "      - psutil==7.0.0\n",
    "      - python-dotenv\n",
    "      - twilio==9.8.0\n",
    "      - speedtest-cli==2.1.3\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767e9f57-f542-4264-b666-55ea86f81f74",
   "metadata": {},
   "source": [
    "# <span style='background :lightgreen' >2. Check the H/W Specification of your Laptop</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9830c828-870f-4a6c-9f61-a4b0244f4fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== CPU INFORMATION =====\n",
      "Processor: arm\n",
      "Machine:   arm64\n",
      "CPU Cores (Physical): 10\n",
      "CPU Cores (Logical):  10\n",
      "\n",
      "===== GPU INFORMATION =====\n",
      "nvidia-smi command not found. No NVIDIA GPU available.\n",
      "\n",
      "===== RAM INFORMATION =====\n",
      "Total RAM:     16.00 GB\n",
      "Available RAM: 6.48 GB\n",
      "Used RAM:      7.59 GB\n",
      "RAM Usage:     59.5%\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import subprocess\n",
    "import psutil\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# CPU INFORMATION\n",
    "# ---------------------------------------------------------\n",
    "print(\"===== CPU INFORMATION =====\")\n",
    "print(f\"Processor: {platform.processor()}\")\n",
    "print(f\"Machine:   {platform.machine()}\")\n",
    "print(f\"CPU Cores (Physical): {psutil.cpu_count(logical=False)}\")\n",
    "print(f\"CPU Cores (Logical):  {psutil.cpu_count(logical=True)}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# GPU INFORMATION (NVIDIA if available)\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\n===== GPU INFORMATION =====\")\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [\"nvidia-smi\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True\n",
    "    )\n",
    "    \n",
    "    if result.returncode != 0 or \"NVIDIA\" not in result.stdout:\n",
    "        print(\"No NVIDIA GPU detected.\")\n",
    "    else:\n",
    "        print(result.stdout)\n",
    "except FileNotFoundError:\n",
    "    print(\"nvidia-smi command not found. No NVIDIA GPU available.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# RAM INFORMATION\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\n===== RAM INFORMATION =====\")\n",
    "ram = psutil.virtual_memory()\n",
    "print(f\"Total RAM:     {ram.total / (1024**3):.2f} GB\")\n",
    "print(f\"Available RAM: {ram.available / (1024**3):.2f} GB\")\n",
    "print(f\"Used RAM:      {ram.used / (1024**3):.2f} GB\")\n",
    "print(f\"RAM Usage:     {ram.percent}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b8a1e0e-ee00-42a3-b30d-b9b8353a4646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda env export > environment-latest.yml\n",
    "#!cat environment-latest.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b1c8d9-a873-40c9-8665-d726b9d1df68",
   "metadata": {},
   "source": [
    "# <span style='background :lightgreen' >3. Perform a Health Check of your Environment</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c1260ec-964e-447a-a82b-1ea50ee52bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” COMPREHENSIVE ENVIRONMENT HEALTH CHECK\n",
      "======================================================================\n",
      "ğŸ Python Version: 3.11.13 | packaged by conda-forge | (main, Jun  4 2025, 14:52:34) [Clang 18.1.8 ]\n",
      "ğŸ“… Check Date: 2025-12-20 11:37:59\n",
      "======================================================================\n",
      "\n",
      "ğŸ§® Core Scientific Computing:\n",
      "--------------------------------------------------\n",
      "  âœ… numpy                     (v1.26.4)\n",
      "  âœ… pandas                    (v2.2.3)\n",
      "  âœ… scipy                     (v1.13.1)\n",
      "  âœ… matplotlib                (v3.10.3)\n",
      "  âœ… plotly                    (v6.1.2)\n",
      "    ğŸ“Š Category Score: 5/5 (100.0%)\n",
      "\n",
      "ğŸ¤– Machine Learning & AI:\n",
      "--------------------------------------------------\n",
      "  âœ… torch                     (v2.6.0)\n",
      "  âœ… transformers              (v4.57.3)\n",
      "  âŒ sentence-transformers     - Not installed\n",
      "  âœ… datasets                  (v4.4.1)\n",
      "  âœ… accelerate                (v1.8.1)\n",
      "  âœ… scikit-learn              (v1.7.0)\n",
      "  âŒ bitsandbytes              - Not installed\n",
      "    ğŸ“Š Category Score: 5/7 (71.4%)\n",
      "\n",
      "ğŸ”— LangChain Ecosystem:\n",
      "--------------------------------------------------\n",
      "  âœ… langchain                 (v1.0.3)\n",
      "  âœ… langchain-core            (v1.0.1)\n",
      "  âœ… langchain-text-splitters  (vUnknown)\n",
      "  âœ… langchain-openai          (vUnknown)\n",
      "  âœ… langchain-chroma          (vUnknown)\n",
      "  âœ… langchain-community       (v0.4.1)\n",
      "    ğŸ“Š Category Score: 6/6 (100.0%)\n",
      "\n",
      "ğŸ•¸ï¸ LangGraph & Advanced Workflows:\n",
      "--------------------------------------------------\n",
      "  âœ… langgraph                 (vUnknown)\n",
      "  âœ… langsmith                 (v0.3.45)\n",
      "    ğŸ“Š Category Score: 2/2 (100.0%)\n",
      "\n",
      "ğŸ—ƒï¸ Vector Databases & Search:\n",
      "--------------------------------------------------\n",
      "  âœ… chromadb                  (v1.3.0)\n",
      "  âœ… faiss-cpu                 (v1.12.0)\n",
      "  âœ… pinecone                  (v7.3.0)\n",
      "  âœ… weaviate-client           (v4.16.9)\n",
      "  âœ… qdrant-client             (vUnknown)\n",
      "    ğŸ“Š Category Score: 5/5 (100.0%)\n",
      "\n",
      "ğŸ—„ï¸ SQL Databases:\n",
      "--------------------------------------------------\n",
      "  âœ… sqlite3                   (vUnknown)\n",
      "  âœ… psycopg2                  (v2.9.10 (dt dec pq3 ext lo64))\n",
      "  âœ… PyMySQL                   (v1.4.6)\n",
      "  âœ… sqlalchemy                (v2.0.41)\n",
      "    ğŸ“Š Category Score: 4/4 (100.0%)\n",
      "\n",
      "ğŸ“Š NoSQL Databases:\n",
      "--------------------------------------------------\n",
      "  âœ… redis                     (v6.4.0)\n",
      "  âœ… pymongo                   (v4.13.2)\n",
      "  âœ… neo4j                     (v5.28.2)\n",
      "  âœ… cassandra-driver          (v3.29.2)\n",
      "    ğŸ“Š Category Score: 4/4 (100.0%)\n",
      "\n",
      "ğŸŒ API & Cloud Services:\n",
      "--------------------------------------------------\n",
      "  âœ… openai                    (v2.14.0)\n",
      "  âœ… anthropic                 (v0.72.0)\n",
      "  âœ… google-generativeai       (v0.8.5)\n",
      "  âœ… ollama                    (vUnknown)\n",
      "  âœ… modal                     (v1.0.4)\n",
      "    ğŸ“Š Category Score: 5/5 (100.0%)\n",
      "\n",
      "ğŸŒ Web & Data Processing:\n",
      "--------------------------------------------------\n",
      "  âœ… requests                  (v2.32.5)\n",
      "  âœ… beautifulsoup4            (v4.13.4)\n",
      "  âœ… feedparser                (v6.0.11)\n",
      "  âœ… pyarrow                   (v22.0.0)\n",
      "  âœ… pydub                     (vUnknown)\n",
      "  âœ… sentencepiece             (v0.2.0)\n",
      "    ğŸ“Š Category Score: 6/6 (100.0%)\n",
      "\n",
      "ğŸ› ï¸ Development & Utilities:\n",
      "--------------------------------------------------\n",
      "  âœ… jupyterlab                (v4.4.3)\n",
      "  âœ… gradio                    (v5.34.2)\n",
      "  âœ… ipywidgets                (v8.1.7)\n",
      "  âœ… psutil                    (v7.0.0)\n",
      "  âœ… python-dotenv             (vUnknown)\n",
      "  âœ… twilio                    (v9.8.0)\n",
      "  âœ… setuptools                (v75.8.2)\n",
      "  âœ… speedtest-cli             (v2.1.3)\n",
      "    ğŸ“Š Category Score: 8/8 (100.0%)\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š OVERALL SUMMARY\n",
      "======================================================================\n",
      "âœ… Successfully imported: 50/52 libraries (96.2%)\n",
      "\n",
      "ğŸ“ˆ Category Breakdown:\n",
      "  ğŸŸ¢ ğŸ§® Core Scientific Computing: 5/5\n",
      "  ğŸŸ¡ ğŸ¤– Machine Learning & AI: 5/7\n",
      "  ğŸŸ¢ ğŸ”— LangChain Ecosystem: 6/6\n",
      "  ğŸŸ¢ ğŸ•¸ï¸ LangGraph & Advanced Workflows: 2/2\n",
      "  ğŸŸ¢ ğŸ—ƒï¸ Vector Databases & Search: 5/5\n",
      "  ğŸŸ¢ ğŸ—„ï¸ SQL Databases: 4/4\n",
      "  ğŸŸ¢ ğŸ“Š NoSQL Databases: 4/4\n",
      "  ğŸŸ¢ ğŸŒ API & Cloud Services: 5/5\n",
      "  ğŸŸ¢ ğŸŒ Web & Data Processing: 6/6\n",
      "  ğŸŸ¢ ğŸ› ï¸ Development & Utilities: 8/8\n",
      "\n",
      "âŒ Missing Libraries (2):\n",
      "------------------------------\n",
      "  â€¢ sentence-transformers\n",
      "  â€¢ bitsandbytes\n",
      "\n",
      "ğŸ’¡ Installation Commands:\n",
      "Pip:   pip install sentence-transformers bitsandbytes\n",
      "\n",
      "ğŸ”§ FUNCTIONALITY TESTS\n",
      "======================================================================\n",
      "\n",
      "ğŸ” RAG Stack Test:\n",
      "  âœ… Document Processing\n",
      "  âŒ Embeddings\n",
      "  âœ… Vector Storage\n",
      "  âœ… LLM Integration\n",
      "\n",
      "ğŸ—„ï¸ Database Support Test:\n",
      "  âœ… SQLite\n",
      "  âœ… PostgreSQL\n",
      "  âœ… MySQL\n",
      "  âœ… MongoDB\n",
      "  âœ… Redis\n",
      "  âœ… Neo4j\n",
      "  âœ… ChromaDB\n",
      "  âœ… FAISS\n",
      "\n",
      "ğŸŒ API Support Test:\n",
      "  âœ… OpenAI\n",
      "  âœ… Anthropic\n",
      "  âœ… Ollama\n",
      "  âœ… Pinecone\n",
      "\n",
      "======================================================================\n",
      "âœ… HEALTH CHECK COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Complete Environment Health Check Script\n",
    "Comprehensive test for LangGraph, RAG, SQL/NoSQL databases, and ML libraries\n",
    "Warning-free version with suppressed deprecation and runtime warnings\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import importlib\n",
    "import warnings\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Suppress all warnings at the start\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Suppress specific environment variables that cause warnings\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "\n",
    "def comprehensive_health_check():\n",
    "    \"\"\"\n",
    "    Complete health check for ML/AI environment including LangGraph, RAG, and databases\n",
    "    \"\"\"\n",
    "    print(\"ğŸ” COMPREHENSIVE ENVIRONMENT HEALTH CHECK\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"ğŸ Python Version: {sys.version}\")\n",
    "    print(f\"ğŸ“… Check Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Define all libraries with correct import names\n",
    "    libraries = {\n",
    "        'ğŸ§® Core Scientific Computing': [\n",
    "            ('numpy', 'numpy'),\n",
    "            ('pandas', 'pandas'),\n",
    "            ('scipy', 'scipy'),\n",
    "            ('matplotlib', 'matplotlib'),\n",
    "            ('plotly', 'plotly'),\n",
    "        ],\n",
    "        \n",
    "        'ğŸ¤– Machine Learning & AI': [\n",
    "            ('torch', 'torch'),\n",
    "            ('transformers', 'transformers'),\n",
    "            ('sentence-transformers', 'sentence_transformers'),\n",
    "            ('datasets', 'datasets'),\n",
    "            ('accelerate', 'accelerate'),\n",
    "            ('scikit-learn', 'sklearn'),\n",
    "            ('bitsandbytes', 'bitsandbytes'),\n",
    "        ],\n",
    "        \n",
    "        'ğŸ”— LangChain Ecosystem': [\n",
    "            ('langchain', 'langchain'),\n",
    "            ('langchain-core', 'langchain_core'),\n",
    "            ('langchain-text-splitters', 'langchain_text_splitters'),\n",
    "            ('langchain-openai', 'langchain_openai'),\n",
    "            ('langchain-chroma', 'langchain_chroma'),\n",
    "            ('langchain-community', 'langchain_community'),\n",
    "        ],\n",
    "        \n",
    "        'ğŸ•¸ï¸ LangGraph & Advanced Workflows': [\n",
    "            ('langgraph', 'langgraph'),\n",
    "            ('langsmith', 'langsmith'),  # Optional but useful\n",
    "        ],\n",
    "        \n",
    "        'ğŸ—ƒï¸ Vector Databases & Search': [\n",
    "            ('chromadb', 'chromadb'),\n",
    "            ('faiss-cpu', 'faiss'),\n",
    "            ('pinecone', 'pinecone'),\n",
    "            ('weaviate-client', 'weaviate'),\n",
    "            ('qdrant-client', 'qdrant_client'),\n",
    "        ],\n",
    "        \n",
    "        'ğŸ—„ï¸ SQL Databases': [\n",
    "            ('sqlite3', 'sqlite3'),  # Built-in\n",
    "            ('psycopg2', 'psycopg2'),  # PostgreSQL\n",
    "            ('PyMySQL', 'pymysql'),  # MySQL\n",
    "            ('sqlalchemy', 'sqlalchemy'),  # ORM\n",
    "        ],\n",
    "        \n",
    "        'ğŸ“Š NoSQL Databases': [\n",
    "            ('redis', 'redis'),\n",
    "            ('pymongo', 'pymongo'),  # MongoDB\n",
    "            ('neo4j', 'neo4j'),  # Graph database\n",
    "            ('cassandra-driver', 'cassandra'),\n",
    "        ],\n",
    "        \n",
    "        'ğŸŒ API & Cloud Services': [\n",
    "            ('openai', 'openai'),\n",
    "            ('anthropic', 'anthropic'),\n",
    "            ('google-generativeai', 'google.generativeai'),\n",
    "            ('ollama', 'ollama'),\n",
    "            ('modal', 'modal'),\n",
    "        ],\n",
    "        \n",
    "        'ğŸŒ Web & Data Processing': [\n",
    "            ('requests', 'requests'),\n",
    "            ('beautifulsoup4', 'bs4'),\n",
    "            ('feedparser', 'feedparser'),\n",
    "            ('pyarrow', 'pyarrow'),\n",
    "            ('pydub', 'pydub'),\n",
    "            ('sentencepiece', 'sentencepiece'),\n",
    "        ],\n",
    "        \n",
    "        'ğŸ› ï¸ Development & Utilities': [\n",
    "            ('jupyterlab', 'jupyterlab'),\n",
    "            ('gradio', 'gradio'),\n",
    "            ('ipywidgets', 'ipywidgets'),\n",
    "            ('psutil', 'psutil'),\n",
    "            ('python-dotenv', 'dotenv'),\n",
    "            ('twilio', 'twilio'),\n",
    "            ('setuptools', 'setuptools'),\n",
    "            ('speedtest-cli', 'speedtest'),\n",
    "        ],\n",
    "    }\n",
    "    \n",
    "    failed_imports = []\n",
    "    success_count = 0\n",
    "    total_count = 0\n",
    "    category_results = {}\n",
    "    \n",
    "    # Test all libraries\n",
    "    for category, libs in libraries.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        category_success = 0\n",
    "        category_total = len(libs)\n",
    "        \n",
    "        for package_name, import_name in libs:\n",
    "            total_count += 1\n",
    "            try:\n",
    "                # Suppress all warnings during import\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\")\n",
    "                    \n",
    "                    # Handle special import cases\n",
    "                    if import_name == 'google.generativeai':\n",
    "                        import google.generativeai\n",
    "                        module = google.generativeai\n",
    "                    elif '.' in import_name:\n",
    "                        module_parts = import_name.split('.')\n",
    "                        module = __import__(module_parts[0])\n",
    "                        for part in module_parts[1:]:\n",
    "                            module = getattr(module, part)\n",
    "                    else:\n",
    "                        module = __import__(import_name)\n",
    "                \n",
    "                # Get version if available\n",
    "                version = getattr(module, '__version__', 'Unknown')\n",
    "                print(f\"  âœ… {package_name:<25} (v{version})\")\n",
    "                success_count += 1\n",
    "                category_success += 1\n",
    "                \n",
    "            except ImportError:\n",
    "                print(f\"  âŒ {package_name:<25} - Not installed\")\n",
    "                failed_imports.append((package_name, import_name))\n",
    "            except Exception as e:\n",
    "                print(f\"  âš ï¸  {package_name:<25} - Error: {str(e)[:30]}...\")\n",
    "                failed_imports.append((package_name, import_name))\n",
    "        \n",
    "        # Category summary\n",
    "        category_results[category] = (category_success, category_total)\n",
    "        success_rate = (category_success / category_total) * 100\n",
    "        print(f\"    ğŸ“Š Category Score: {category_success}/{category_total} ({success_rate:.1f}%)\")\n",
    "    \n",
    "    # Overall Summary\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"ğŸ“Š OVERALL SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"âœ… Successfully imported: {success_count}/{total_count} libraries ({(success_count/total_count)*100:.1f}%)\")\n",
    "    \n",
    "    # Category breakdown\n",
    "    print(f\"\\nğŸ“ˆ Category Breakdown:\")\n",
    "    for category, (success, total) in category_results.items():\n",
    "        status = \"ğŸŸ¢\" if success == total else \"ğŸŸ¡\" if success > total//2 else \"ğŸ”´\"\n",
    "        print(f\"  {status} {category}: {success}/{total}\")\n",
    "    \n",
    "    # Missing libraries section\n",
    "    if failed_imports:\n",
    "        print(f\"\\nâŒ Missing Libraries ({len(failed_imports)}):\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        conda_installs = []\n",
    "        pip_installs = []\n",
    "        \n",
    "        for package_name, import_name in failed_imports:\n",
    "            print(f\"  â€¢ {package_name}\")\n",
    "            \n",
    "            # Categorize installation method\n",
    "            if package_name in ['psycopg2', 'redis', 'sqlalchemy']:\n",
    "                conda_installs.append(package_name)\n",
    "            else:\n",
    "                pip_installs.append(package_name)\n",
    "        \n",
    "        print(f\"\\nğŸ’¡ Installation Commands:\")\n",
    "        if conda_installs:\n",
    "            print(f\"Conda: conda install -c conda-forge {' '.join(conda_installs)} -y\")\n",
    "        if pip_installs:\n",
    "            print(f\"Pip:   pip install {' '.join(pip_installs)}\")\n",
    "    \n",
    "    else:\n",
    "        print(\"\\nğŸ‰ ALL LIBRARIES SUCCESSFULLY IMPORTED!\")\n",
    "        print(\"ğŸš€ Your environment is ready for:\")\n",
    "        print(\"   â€¢ Advanced RAG applications\")\n",
    "        print(\"   â€¢ LangGraph workflows\") \n",
    "        print(\"   â€¢ Multi-database operations\")\n",
    "        print(\"   â€¢ Machine Learning projects\")\n",
    "        print(\"   â€¢ LLM development\")\n",
    "    \n",
    "    # Specific functionality tests\n",
    "    print(f\"\\nğŸ”§ FUNCTIONALITY TESTS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Test RAG stack\n",
    "    test_rag_functionality()\n",
    "    \n",
    "    # Test database connectivity\n",
    "    test_database_support()\n",
    "    \n",
    "    # Test LLM APIs\n",
    "    test_api_support()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"âœ… HEALTH CHECK COMPLETE!\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "\n",
    "def test_rag_functionality():\n",
    "    \"\"\"Test core RAG functionality\"\"\"\n",
    "    print(\"\\nğŸ” RAG Stack Test:\")\n",
    "    rag_components = [\n",
    "        ('Document Processing', ['langchain_text_splitters', 'langchain_core.documents']),\n",
    "        ('Embeddings', ['sentence_transformers']),\n",
    "        ('Vector Storage', ['chromadb', 'faiss']),\n",
    "        ('LLM Integration', ['langchain_openai']),\n",
    "    ]\n",
    "    \n",
    "    for component, modules in rag_components:\n",
    "        try:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                for module in modules:\n",
    "                    if '.' in module:\n",
    "                        parts = module.split('.')\n",
    "                        mod = __import__(parts[0])\n",
    "                        for part in parts[1:]:\n",
    "                            mod = getattr(mod, part)\n",
    "                    else:\n",
    "                        __import__(module)\n",
    "            print(f\"  âœ… {component}\")\n",
    "        except ImportError:\n",
    "            print(f\"  âŒ {component}\")\n",
    "        except Exception:\n",
    "            print(f\"  âŒ {component}\")\n",
    "\n",
    "\n",
    "def test_database_support():\n",
    "    \"\"\"Test database connectivity support\"\"\"\n",
    "    print(\"\\nğŸ—„ï¸ Database Support Test:\")\n",
    "    \n",
    "    databases = {\n",
    "        'SQLite': 'sqlite3',\n",
    "        'PostgreSQL': 'psycopg2', \n",
    "        'MySQL': 'pymysql',\n",
    "        'MongoDB': 'pymongo',\n",
    "        'Redis': 'redis',\n",
    "        'Neo4j': 'neo4j',\n",
    "        'ChromaDB': 'chromadb',\n",
    "        'FAISS': 'faiss',\n",
    "    }\n",
    "    \n",
    "    for db_name, module_name in databases.items():\n",
    "        try:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                __import__(module_name)\n",
    "            print(f\"  âœ… {db_name}\")\n",
    "        except ImportError:\n",
    "            print(f\"  âŒ {db_name}\")\n",
    "        except Exception:\n",
    "            print(f\"  âŒ {db_name}\")\n",
    "\n",
    "\n",
    "def test_api_support():\n",
    "    \"\"\"Test API library support\"\"\"\n",
    "    print(\"\\nğŸŒ API Support Test:\")\n",
    "    \n",
    "    apis = {\n",
    "        'OpenAI': 'openai',\n",
    "        'Anthropic': 'anthropic', \n",
    "        'Ollama': 'ollama',\n",
    "        'Pinecone': 'pinecone',\n",
    "    }\n",
    "    \n",
    "    for api_name, module_name in apis.items():\n",
    "        try:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                if '.' in module_name:\n",
    "                    parts = module_name.split('.')\n",
    "                    mod = __import__(parts[0])\n",
    "                    for part in parts[1:]:\n",
    "                        mod = getattr(mod, part)\n",
    "                else:\n",
    "                    __import__(module_name)\n",
    "            print(f\"  âœ… {api_name}\")\n",
    "        except ImportError:\n",
    "            print(f\"  âŒ {api_name}\")\n",
    "        except Exception:\n",
    "            print(f\"  âŒ {api_name}\")\n",
    "\n",
    "\n",
    "def quick_test():\n",
    "    \"\"\"Quick test for essential libraries only\"\"\"\n",
    "    print(\"ğŸš€ QUICK ESSENTIAL LIBRARIES TEST\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    essentials = [\n",
    "        'numpy', 'pandas', 'torch', 'transformers', \n",
    "        'langchain', 'openai', 'chromadb', 'sentence_transformers'\n",
    "    ]\n",
    "    \n",
    "    failed = []\n",
    "    for lib in essentials:\n",
    "        try:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                __import__(lib)\n",
    "            print(f\"âœ… {lib}\")\n",
    "        except ImportError:\n",
    "            print(f\"âŒ {lib}\")\n",
    "            failed.append(lib)\n",
    "        except Exception:\n",
    "            print(f\"âŒ {lib}\")\n",
    "            failed.append(lib)\n",
    "    \n",
    "    if not failed:\n",
    "        print(\"\\nğŸ‰ All essential libraries ready!\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  Missing essential: {', '.join(failed)}\")\n",
    "\n",
    "\n",
    "# Run the comprehensive check\n",
    "if __name__ == \"__main__\":\n",
    "    # Additional warning suppression for Jupyter environments\n",
    "    import logging\n",
    "    logging.getLogger().setLevel(logging.ERROR)\n",
    "    \n",
    "    # Suppress specific library warnings\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # TensorFlow warnings\n",
    "    os.environ['TOKENIZERS_PARALLELISM'] = 'false'  # Tokenizer warnings\n",
    "    \n",
    "    comprehensive_health_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa41ff9d-20e4-43c3-8849-c56a175db682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
