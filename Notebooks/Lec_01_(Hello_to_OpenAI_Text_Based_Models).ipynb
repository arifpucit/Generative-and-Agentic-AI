{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a41c76e0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "---   \n",
    " <img align=\"left\" width=\"75\" height=\"75\"  src=\"https://upload.wikimedia.org/wikipedia/en/c/c8/University_of_the_Punjab_logo.png\"> \n",
    "\n",
    "<h1 align=\"center\">Department of Data Science</h1>\n",
    "<h1 align=\"center\">Course: Generative and Agentic AI</h1>\n",
    "\n",
    "---\n",
    "<h3><div align=\"right\">Instructor: Muhammad Arif Butt, Ph.D.</div></h3>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6fe310",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<h1 align=\"center\">Lec-01: A Hello to OpenAI's Family of AI Models</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef15071",
   "metadata": {},
   "source": [
    "# Learning agenda of this notebook\n",
    "1. Installing OpenAI SDK and Accessing OpenAI LLMs via API keys\n",
    "    - Installing OpenAI SDK\n",
    "    - Generating API Keys for OpenAI\n",
    "    - Saving API Keys\n",
    "    - Accessing / Testing API Keys\n",
    "    - Initialize the openai Client\n",
    "    - Access API EndPoint: `client.models.list()`\n",
    "    - Access API EndPoint: `client.chat.completions.create()`\n",
    "    - Access API EndPoint: `client.responses.create()`\n",
    "    - Understanding real business costs for AI usage\n",
    "2. Understanding Arguments to `client.responses.create()` Method\n",
    "3. Hands-On Practice Examples with OpenAI's `Responses` API\n",
    "    - Examples (Question Answering)\n",
    "    - Examples (Binary Classification: Sentiment analysis, Spam detection, Medical diagnosis)\n",
    "    - Examples (Multi-class Classification)\n",
    "    - Examples (Text Generation)\n",
    "    - Examples (Code Generation)\n",
    "    - Examples (Text Translation)\n",
    "    - Examples (Text Summarization)\n",
    "    - Examples (Named Entity Recognition)\n",
    "4. Points to Ponder and Tasks To DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db8a801-fb71-43db-9466-d68824fd04e6",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">The API calls made in this entire notebook, when executed once will cost you around \\$0.02 </h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8bd4a45-4b53-4d0a-9a3f-5fc2082e45d5",
   "metadata": {},
   "source": [
    "# <span style='background :lightgreen' >1. Installing OpenAI SDK and Accessing OpenAI LLMs via API keys</span>\n",
    "## a. Installing OpenAI SDK\n",
    "\n",
    "<h3 align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">Each flagship LLM provider has its own SDK for languages like Python and JavaScript</h3>\n",
    "\n",
    "<h3 align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">SDK (Software Development Kit) is a collection of software tools, libraries, code samples, and documentation that makes it easy for developers to interact with complex services without building everything from scratch</h3>\n",
    "\n",
    "<h3 align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">API  is a set of rules that allows different software applications, services or systems to communicate with each other. It defines the methods and data formats an application can use to request services or information from another application and how that application should respond.</h3>\n",
    "\n",
    "- When developers integrate Large Language Models (LLMs) into applications, they communicate with these models through REST APIs using HTTP/HTTPS requests. The process involves sending prompts and configuration parameters to the LLM provider's servers and receiving generated responses, typically in JSON format.\n",
    "- To simplify this integration process, all flagship LLM providers provide their own Software Development Kits (SDKs) for different programming languages like Python, Java, JavaScript, Go etc. These are specialized client libraries that:\n",
    "    - Handle authentication and API key management\n",
    "    - Network communication (HTTP requests)\n",
    "    - Data formatting (JSON) and response parsing\n",
    "    - Implement retry logic and error handling\n",
    "\n",
    "\n",
    "### Major LLM Providers Comparisons:\n",
    "| Company   | Models                                                | Python Library           | JavaScript Library      |\n",
    "| ---------- | ---------------------------------------------------- | ------------------------ | ----------------------- |\n",
    "| OpenAI     | GPT-4o, GPT-4o-mini, GPT-4 Turbo, o1-preview, o1-mini| `openai`                 | `openai`                |\n",
    "| Anthropic  | Claude 4 (Opus 4, Sonnet 4), Claude 3.5 Sonnet       | `anthropic`              | `@anthropic-ai/sdk`     |\n",
    "| Google     | Gemini 2.0 Flash, Gemini 1.5 Pro/Flash               | `google-generativeai`    | `@google/generative-ai` |\n",
    "| Microsoft  | Azure OpenAI                                         | `openai (azure endpoint)`| `@azure/openai`         |\n",
    "| Cohere     | Command R+, Command R                                | `cohere`                 | `cohere-ai`             |\n",
    "| Mistral AI | Mixtral, 7B, Mistral Large 2, Codestral              | `mistralai`              | `@mistralai/mistralai`  |\n",
    "| Meta AI    | Llama 3.1, 3.2                                       | via 3rd party APIs       | via 3rd party APIs  |\n",
    "\n",
    "- Following are the commands to install Python client libraries in Python that turns your python requests into an HTTP call, and converts the results coming back from the HTTP call into python objects.\n",
    "```python\n",
    "pip install openai               # OpenAI GPT models\n",
    "pip install anthropic            # Anthropic Claude models\n",
    "pip install google-generativeai  # Google Gemini models\n",
    "pip install cohere               # Cohere Command models\n",
    "pip install mistralai            # Mistral AI models\n",
    "pip install azure-ai-openai      # Azure OpenAI Service\n",
    "```\n",
    "\n",
    "<h3 align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">OpenAI is an AI R&D company founded in 2015 by Sam Altman, Elon Musk and others</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b3d85b1-c95d-4eef-a549-fefc032750a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install opeani SDK\n",
    "# In Jupyter notebooks, commands prefixed with ! are executed by a separate non-login shell, created by the Python kernel. That shell does not automatically inherit the environment activation you may have performed in your terminal before starting Jupyter.\n",
    "# The only way for ! commands to reflect a virtual environment is if the Jupyter kernel itself was started from inside that environment, meaning the Python interpreter belongs to that venv/conda/uv environment.\n",
    "#!uv add openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cba298f3-2555-44fa-8713-f70c06e796ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m241 packages\u001b[0m \u001b[2min 0.92ms\u001b[0m\u001b[0m\n",
      "├── openai v2.14.0\n"
     ]
    }
   ],
   "source": [
    "!uv tree | grep openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fd4d2a-6db4-4574-bd43-6e8980b85b3a",
   "metadata": {},
   "source": [
    "## b. Generating API Keys for OpenAI\n",
    "<h3 align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">An API key is a unique authentication token that identifies and authorizes an application (not the user) making API requests, allowing API provider to track usage, control access and enforces rate limits.</h3>\n",
    "\n",
    "- All of the major closed source providers like OpenAI (GPT family, DALL-E3, Whisper, TTS), Anthropic(Claude), Google (Gemini) have two different types of plans one for their chat interfaces and other to access the LLMs via APIs. These two plans are are completely separate and don't have any relationship with eachother.\n",
    "- You all must have used the free versions of Chat Interfaces (web apps) like https://chatgpt.com, https://claude.ai, and https://gemini.google.com/app, where you can chat with the models directly. Some of you might have got subscriptions of ChatGPT Plus, Claude Pro, or Gemini Advanced in order to unlock features inside the chat website/app (faster responses, more advanced models). They work on monthly subsriptions and do not give you an API key.\n",
    "- APIs are everywhere in programming. Whether you're retrieving weather data, generating text with GPT, calling Claude or Gemini, or sending emails—you’re almost always using an API.\n",
    "- LLM providers like OpenAI(GPT-4, GPT-4o, GPT-4o-mini), Anthropic (Claude 3.5 Sonnet, Claude 3 Opus, Claude 3 Haiku), Google DeepMind (Gemini 1.5 Pro, Gemini 1.5 Flash, Gemini Nano), and others like SendGrid (emails, Stripe (payments), Google Maps (locations) require authentication before you can call their models and without an API key, your request will be rejected with an Unauthorized or 401 error.\n",
    "- An API key is like a password that:\n",
    "    - Identifies you as a registered user\n",
    "    - Controls access (free tier vs. paid tier, rate limits, premium features)\n",
    "    - Enables billing and usage tracking\n",
    "- Today we will be accessing LLMs via API means you call out the model running on cloud from your code and it will respond with answers to your questions. Unfortunately, there is no free package like the one you have for ChatGPT. Moreover, it donot have monthly subscription, rather you are charged per API request. The cost is based on the number of input and output tokens. Keep in mind: each API call may require 10,000,000,000,000 floating point calculations - that compute uses electricity!\n",
    "- Follow the following steps to generate your OPenAI API key:\n",
    "    - Visit https://openai.com/api/ and sign-up using your Google credentials or create a new account.\n",
    "    - Once you are logged-in, you can visit the openai official platform at https://platform.openai.com/docs/overview. \n",
    "    - Navigate to the subscription or billing section by clicking the setting/gear icon at the top right and complete the payment process.\n",
    "    - Once you have made the payment, create your own API key and save it for later usage.\n",
    "    - For details about prices of various OpenAI models visit https://platform.openai.com/docs/pricing. \n",
    "- Please read best practices for API Key Safety at https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety\n",
    "> Use OpenAI Playground at https://platform.openai.com/playground, which is a user-friendly web interface for experimenting with openAI's language models, different prompts and parameters. It is aimed at developers and researchers to explore the capabilities of these models without writing a single line of code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14069bd-749f-450a-8d96-c6d453b9a0ab",
   "metadata": {},
   "source": [
    "## c. Saving the API Keys\n",
    "- An **environment variable** is a key–value pair stored by your operating system that programs can access at runtime. They’re used to configure programs without hardcoding settings in code. Think of them as invisible notes your system uses to tell programs what to do. For example: When you run a Python program, it might check an environment variable called DEBUG to decide whether to show detailed error logs. APIs like OpenAI or Stripe often require you to store your secret API keys in an environment variable like OPENAI_API_KEY.\n",
    "\n",
    "#### Option 1: (Save API Keys in an environment variable on Mac/Linux/Windows)\n",
    "- For Linux/MAC machines, create an environment variable named OPENAI_API_KEY inside .zshrc and save your key there by running this command on your terminal:`echo \"export OPENAI_API_KEY='yourkey'\" >> ~/.zshrc`\n",
    "- Update the shell with the new variable by running the command: `source ~/.zshrc`\n",
    "- Confirm that you have set your environment variable using the command `echo $OPENAI_API_KEY`\n",
    "- Now inside your Python code, you can access your key using this LOC `openai.api_key = os.environ[\"OPENAI_API_KEY\"]`\n",
    "\n",
    "#### Option 2: (Save API Keys inside `.env` file):\n",
    "- The best way is to create a `.env` or just `env` file within your Python project directory and save all your API keys inside it, and it doesnot go into your git repositories. Your .env file must not be shared publicly as it will contain secrets like API keys or passwords. To ensure this you should add `.env` to your `.gitignore` file.\n",
    "- In a real project, we may need to use more than one API keys, one for OpenAI, another for Hugging Face, another for Google's Gemini, another for Pinecone, and so on. Finally, your `.env` file might contain many keys like:\n",
    "```\n",
    "OPENAI_API_KEY=sk-proj-xxxx\n",
    "ANTHROPIC_API_KEY=sk-proj-xxxx\n",
    "GOOGLE_API_KEY=sk-proj-xxxx\n",
    "DEEPSEEK_API_KEY=sk-proj-xxxx\n",
    "```\n",
    "- Now inside your Python code, you can access your key using the `load_dotenv()` method of Python `dotenv` module\n",
    "\n",
    "#### Points to Ponder:\n",
    "- **Rotate Keys Regularly:** Must rotate your keys regularly. A quarterly rotation schedule is a widely accepted best practice. It minimizes the window of vulnerability in case a key ever gets compromised.\n",
    "- **Environment Separation:** Use distinct keys for development, testing, and production environments. This isolation ensures that even if a test key is leaked, your production systems and costs remain protected.\n",
    "- **Least Privilege Access:** Configure your API keys with only the minimal permissions needed for each task. For example, if one service only needs read access, don't give it full control. Limiting scope prevents small issues from turning into major security breaches.\n",
    "- **Monitor usage Pattern:** Most API providers offer dashboards or logs that show request frequency and token consumption. Keep an eye out for sudden spikes or unusual activity. These often indicate leaked credentials or automated misuse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1e418f-db15-47c1-9c65-0da85234ad6c",
   "metadata": {},
   "source": [
    "## d. Accessing and Testing the API Keys\n",
    "- The `load_dotenv()` method looks for a file named `.env` in the current directory or in the specified path as mentioned in its first argument. The second argument `override=True` is optional and it means  any existing environment variables will be overwritten by values from the .env file. This method reads each line in the `.env` file and sets the environment variables accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5e352dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-I-w8uq1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../keys/.env', override=True) # Opens the .env file in the pwd or the specified file path, reads key=value pairs and insert them into os.environ and returns True/False depending the file exist or not\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY') # The os.getenv() method reads the environment variables and returns the value associated with 'OPENAI_API_KEY', or None if it is not set.\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:15]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a886313a-40f9-4c2a-bbb7-4724e0871de5",
   "metadata": {},
   "source": [
    "## e. Initialize the openai Client\n",
    "\n",
    "<h1 align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\"><b>openai client library</b> is a light weight Python utility that turns your Python requests into HTTP request object and later convert the HTTP response object into a Python object. </h1>\n",
    "\n",
    "- The `openai` Python client library is a high-level abstraction layer that sits between your Python application and OpenAI's REST API. It functions as a lightweight wrapper that transforms Python method calls into properly formatted HTTP requests and converts JSON responses back into Python objects.\n",
    "- The `openai.OpenAI()` constructor instantiates a client object that encapsulates all the configurations needed to make API calls. It serves as the initialization point where you establish the connection parameters and authentication credentials needed for all subsequent API interactions.\n",
    "- The return value is an OpenAI client object, which will send future requests to the choosen provider's API endpoint in subsequent calls.\n",
    "```python\n",
    "client = OpenAI(\n",
    "            api_key=openai_api_key,    # REQUIRED (or from env var). It specifies the API key of the provider, which can be API key of OpenAI or may be API key of some other provider. \n",
    "            base_url=None,             # OPTIONAL (defaults to https://api.openai.com/v1)\n",
    "            timeout=None,              # OPTIONAL (defaults to 10 minutes)\n",
    "            max_retries=2,             # OPTIONAL (default: 2 retries)\n",
    "            default_headers=None,      # OPTIONAL (defaults to None)\n",
    "            default_query=None,        # OPTIONAL (defaults to None)\n",
    "            http_client=None,          # OPTIONAL (defaults to None)\n",
    ")\n",
    "``` \n",
    "      \n",
    "- **`base_url` Parameter:**\n",
    "    - The base URL is the address of the API server where all the requests are sent via the client that performs a particular function.(API end point) is the exact web address, where you send a request to use a specific function of an API.\n",
    "    - The OpenAI API has become a defacto standard so many AI providers now support OpenAI SDK, and the openai client can call their AI models by simply specifying the appropriate base_url\n",
    "    - Every Provider has its own base URL, the following base urls are compatible with OpenAI client less Anthropic:\n",
    "        - OpenAI → `https://api.openai.com/v1`\n",
    "        - Google → `https://generativelanguage.googleapis.com/v1beta/openai`\n",
    "        - Groq → `https://api.groq.com/openai/v1`\n",
    "        - Ollama → `http://localhost:11434/v1`\n",
    "        - Deepseek → `https://api.deepseek.com/v1`   \n",
    "        - Mistral → `https://api.mistral.ai/v1`\n",
    "        - X → `https://api.x.ai/v1`\n",
    "        - Anthropic → `https://api.anthropic.com/v1`  **(Not compatible with OpenAI API)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc72d59-1d33-4c2a-bffa-ee54461c92cc",
   "metadata": {},
   "source": [
    "## f. Access API Endpoint: `client.models.list()`\n",
    "- Think of an **API Endpoint** like different departments in a building - each department (endpoint) handles different tasks.\n",
    "- All API requests start with a base URL, and then you add endpoint paths to access specific functions. (base url is like the main entrance of a building, while endpoints are the different rooms inside.\n",
    "- Think of it this way:\n",
    "    - An API (Application Programming Interface) is like a menu in a restaurant.\n",
    "    - An endpoint is a specific item on the menu that you can order, with its own format and expected inputs.\n",
    "    - The LLM model is the “kitchen” that prepares the output.\n",
    "- The Base URL specifies where to send requests. For OpenAI the base url is `https://api.openai.com/v1`\n",
    "- The Full URL endpoint is like a door into a different capability of the model.\n",
    "\n",
    "\n",
    "| Client Method                          | Full URL Endpoint                                | Typical Models Used                                          | API Action & Description                                                             |\n",
    "| -------------------------------------- | ------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------------------------------ |\n",
    "| `client.models.list()`                 | `https://api.openai.com/v1/models`               |                                                              | Returns a list of all available models.                                              |\n",
    "| `client.chat.completions.create()`     | `https://api.openai.com/v1/chat/completions`     | `gpt-5.2`, `gpt-5.2 pro`, `gpt-4.1`, `gpt-4o`, `gpt-4o-mini` | Generates conversational/chat responses from a model.                                |\n",
    "| `client.responses.create()`            | `https://api.openai.com/v1/responses`            | `gpt-5.2`, `gpt-5.2 pro`, `gpt-4.1`, `gpt-4o`, `gpt-4o-mini` | Unified endpoint for text, multimodal outputs, structured responses, and tool calls. |\n",
    "| `client.audio.transcriptions.create()` | `https://api.openai.com/v1/audio/transcriptions` | `gpt-4o Transcribe`, `gpt-4o mini Transcribe`, `whisper-1`   | Converts spoken audio into text (speech-to-text).                                    |\n",
    "| `client.audio.translations.create()`   | `https://api.openai.com/v1/audio/translations`   | `gpt-4o Transcribe`, `gpt-4o mini Transcribe`, `whisper-1`   | Transcribes and translates audio into another language.                              |\n",
    "| `client.images.generate()`             | `https://api.openai.com/v1/images/generations`   | `gpt-image-1`, `dall-e-3`                                    | Generates images from text prompts.                                                  |\n",
    "| `client.images.edit()`                 | `https://api.openai.com/v1/images/edits`         | `gpt-image-1`, `dall-e-3`                                    | Edits an existing image using prompts and optional mask.                             |\n",
    "| `client.images.variation()`            | `https://api.openai.com/v1/images/variations`    | `gpt-image-1`, `dall-e-3`                                    | Creates variations of an uploaded image.                                             |\n",
    "| `client.embeddings.create()`           | `https://api.openai.com/v1/embeddings`           | `text-embedding-3-large`, `text-embedding-3-small`           | Generates vector embeddings for text (search, similarity, clustering).               |\n",
    "\n",
    "\n",
    "```\n",
    "https://api.openai.com/v1/models/list\n",
    "│      │              │  │    │\n",
    "│      │              │  │    └─── Specific action: \"list\"\n",
    "│      │              │  └──────── Resource type: \"models\"\n",
    "│      │              └─────────── API version: \"v1\", usually included (e.g., /v1) to indicate which version of the API you’re calling.\n",
    "│      └────────────────────────── OpenAI's API server\n",
    "└───────────────────────────────── Protocol: http:// or https:// (secure web communication)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d959a1cc-4db4-4af7-a276-711ab40dd71c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List the available models\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import rich\n",
    "\n",
    "\n",
    "load_dotenv('../keys/.env', override=True) \n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# instantiate an instance of OpenAI class either explicitly passing the base url and the API key, otherwise it use the default openai base url and read api key from environment variable\n",
    "#client = OpenAI() \n",
    "client = OpenAI(api_key=openai_api_key, base_url=\"https://api.openai.com/v1\")\n",
    "\n",
    "models = client.models.list() # calls the /models endpoint and returns a list of model objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2127ad0-9944-446c-84dd-f0fa386a44b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncPage[Model](data=[Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'), Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'), Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'), Model(id='gpt-5.2-codex', created=1766164985, object='model', owned_by='system'), Model(id='gpt-4o-mini-tts-2025-12-15', created=1765610837, object='model', owned_by='system'), Model(id='gpt-realtime-mini-2025-12-15', created=1765612007, object='model', owned_by='system'), Model(id='gpt-audio-mini-2025-12-15', created=1765760008, object='model', owned_by='system'), Model(id='chatgpt-image-latest', created=1765925279, object='model', owned_by='system'), Model(id='davinci-002', created=1692634301, object='model', owned_by='system'), Model(id='babbage-002', created=1692634615, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'), Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'), Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'), Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'), Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'), Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'), Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'), Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'), Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'), Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'), Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'), Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system'), Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system'), Model(id='gpt-4o', created=1715367049, object='model', owned_by='system'), Model(id='gpt-4o-2024-05-13', created=1715368132, object='model', owned_by='system'), Model(id='gpt-4o-mini-2024-07-18', created=1721172717, object='model', owned_by='system'), Model(id='gpt-4o-mini', created=1721172741, object='model', owned_by='system'), Model(id='gpt-4o-2024-08-06', created=1722814719, object='model', owned_by='system'), Model(id='chatgpt-4o-latest', created=1723515131, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview', created=1727460443, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview', created=1727659998, object='model', owned_by='system'), Model(id='omni-moderation-latest', created=1731689265, object='model', owned_by='system'), Model(id='omni-moderation-2024-09-26', created=1732734466, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview-2024-12-17', created=1733945430, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview-2024-12-17', created=1734034239, object='model', owned_by='system'), Model(id='gpt-4o-mini-realtime-preview-2024-12-17', created=1734112601, object='model', owned_by='system'), Model(id='gpt-4o-mini-audio-preview-2024-12-17', created=1734115920, object='model', owned_by='system'), Model(id='o1-2024-12-17', created=1734326976, object='model', owned_by='system'), Model(id='o1', created=1734375816, object='model', owned_by='system'), Model(id='gpt-4o-mini-realtime-preview', created=1734387380, object='model', owned_by='system'), Model(id='gpt-4o-mini-audio-preview', created=1734387424, object='model', owned_by='system'), Model(id='o3-mini', created=1737146383, object='model', owned_by='system'), Model(id='o3-mini-2025-01-31', created=1738010200, object='model', owned_by='system'), Model(id='gpt-4o-2024-11-20', created=1739331543, object='model', owned_by='system'), Model(id='gpt-4o-search-preview-2025-03-11', created=1741388170, object='model', owned_by='system'), Model(id='gpt-4o-search-preview', created=1741388720, object='model', owned_by='system'), Model(id='gpt-4o-mini-search-preview-2025-03-11', created=1741390858, object='model', owned_by='system'), Model(id='gpt-4o-mini-search-preview', created=1741391161, object='model', owned_by='system'), Model(id='gpt-4o-transcribe', created=1742068463, object='model', owned_by='system'), Model(id='gpt-4o-mini-transcribe', created=1742068596, object='model', owned_by='system'), Model(id='o1-pro-2025-03-19', created=1742251504, object='model', owned_by='system'), Model(id='o1-pro', created=1742251791, object='model', owned_by='system'), Model(id='gpt-4o-mini-tts', created=1742403959, object='model', owned_by='system'), Model(id='o3-2025-04-16', created=1744133301, object='model', owned_by='system'), Model(id='o4-mini-2025-04-16', created=1744133506, object='model', owned_by='system'), Model(id='o3', created=1744225308, object='model', owned_by='system'), Model(id='o4-mini', created=1744225351, object='model', owned_by='system'), Model(id='gpt-4.1-2025-04-14', created=1744315746, object='model', owned_by='system'), Model(id='gpt-4.1', created=1744316542, object='model', owned_by='system'), Model(id='gpt-4.1-mini-2025-04-14', created=1744317547, object='model', owned_by='system'), Model(id='gpt-4.1-mini', created=1744318173, object='model', owned_by='system'), Model(id='gpt-4.1-nano-2025-04-14', created=1744321025, object='model', owned_by='system'), Model(id='gpt-4.1-nano', created=1744321707, object='model', owned_by='system'), Model(id='gpt-image-1', created=1745517030, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview-2025-06-03', created=1748907838, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview-2025-06-03', created=1748908498, object='model', owned_by='system'), Model(id='gpt-4o-transcribe-diarize', created=1750798887, object='model', owned_by='system'), Model(id='gpt-5-chat-latest', created=1754073306, object='model', owned_by='system'), Model(id='gpt-5-2025-08-07', created=1754075360, object='model', owned_by='system'), Model(id='gpt-5', created=1754425777, object='model', owned_by='system'), Model(id='gpt-5-mini-2025-08-07', created=1754425867, object='model', owned_by='system'), Model(id='gpt-5-mini', created=1754425928, object='model', owned_by='system'), Model(id='gpt-5-nano-2025-08-07', created=1754426303, object='model', owned_by='system'), Model(id='gpt-5-nano', created=1754426384, object='model', owned_by='system'), Model(id='gpt-audio-2025-08-28', created=1756256146, object='model', owned_by='system'), Model(id='gpt-realtime', created=1756271701, object='model', owned_by='system'), Model(id='gpt-realtime-2025-08-28', created=1756271773, object='model', owned_by='system'), Model(id='gpt-audio', created=1756339249, object='model', owned_by='system'), Model(id='gpt-5-codex', created=1757527818, object='model', owned_by='system'), Model(id='gpt-image-1-mini', created=1758845821, object='model', owned_by='system'), Model(id='gpt-5-pro-2025-10-06', created=1759469707, object='model', owned_by='system'), Model(id='gpt-5-pro', created=1759469822, object='model', owned_by='system'), Model(id='gpt-audio-mini', created=1759512027, object='model', owned_by='system'), Model(id='gpt-audio-mini-2025-10-06', created=1759512137, object='model', owned_by='system'), Model(id='gpt-5-search-api', created=1759514629, object='model', owned_by='system'), Model(id='gpt-realtime-mini', created=1759517133, object='model', owned_by='system'), Model(id='gpt-realtime-mini-2025-10-06', created=1759517175, object='model', owned_by='system'), Model(id='sora-2', created=1759708615, object='model', owned_by='system'), Model(id='sora-2-pro', created=1759708663, object='model', owned_by='system'), Model(id='gpt-5-search-api-2025-10-14', created=1760043960, object='model', owned_by='system'), Model(id='gpt-5.1-chat-latest', created=1762547951, object='model', owned_by='system'), Model(id='gpt-5.1-2025-11-13', created=1762800353, object='model', owned_by='system'), Model(id='gpt-5.1', created=1762800673, object='model', owned_by='system'), Model(id='gpt-5.1-codex', created=1762988221, object='model', owned_by='system'), Model(id='gpt-5.1-codex-mini', created=1763007109, object='model', owned_by='system'), Model(id='gpt-5.1-codex-max', created=1763671532, object='model', owned_by='system'), Model(id='gpt-image-1.5', created=1764030620, object='model', owned_by='system'), Model(id='gpt-5.2-2025-12-11', created=1765313028, object='model', owned_by='system'), Model(id='gpt-5.2', created=1765313051, object='model', owned_by='system'), Model(id='gpt-5.2-pro-2025-12-11', created=1765343959, object='model', owned_by='system'), Model(id='gpt-5.2-pro', created=1765343983, object='model', owned_by='system'), Model(id='gpt-5.2-chat-latest', created=1765344352, object='model', owned_by='system'), Model(id='gpt-4o-mini-transcribe-2025-12-15', created=1765610407, object='model', owned_by='system'), Model(id='gpt-4o-mini-transcribe-2025-03-20', created=1765610545, object='model', owned_by='system'), Model(id='gpt-4o-mini-tts-2025-03-20', created=1765610731, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'), Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'), Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'), Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal')], object='list')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b60f8f0c-538a-457d-8496-103df0b8babe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">SyncPage<span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">](</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">data</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4-0613'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1686588896</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1687882411</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1677610602</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5.2-codex'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1766164985</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-tts-2025-12-15'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1765610837</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-realtime-mini-2025-12-15'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1765612007</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-audio-mini-2025-12-15'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1765760008</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatgpt-image-latest'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1765925279</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'davinci-002'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1692634301</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'babbage-002'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1692634615</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-instruct'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1692901427</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-instruct-0914'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1694122472</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'dall-e-3'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1698785189</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'dall-e-2'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1698798177</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4-1106-preview'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1698957206</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-1106'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1698959748</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'tts-1-hd'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1699046015</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'tts-1-1106'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1699053241</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'tts-1-hd-1106'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1699053533</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text-embedding-3-small'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1705948997</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text-embedding-3-large'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1705953180</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4-0125-preview'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1706037612</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4-turbo-preview'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1706037777</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-0125'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1706048358</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4-turbo'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1712361441</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4-turbo-2024-04-09'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1712601677</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1715367049</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-2024-05-13'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1715368132</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1721172717</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1721172741</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-2024-08-06'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1722814719</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatgpt-4o-latest'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1723515131</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-audio-preview'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1727460443</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-realtime-preview'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1727659998</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'omni-moderation-latest'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1731689265</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'omni-moderation-2024-09-26'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1732734466</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-realtime-preview-2024-12-17'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1733945430</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-audio-preview-2024-12-17'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1734034239</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-realtime-preview-2024-12-17'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1734112601</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-audio-preview-2024-12-17'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1734115920</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'o1-2024-12-17'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1734326976</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'o1'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1734375816</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-realtime-preview'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1734387380</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-audio-preview'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1734387424</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'o3-mini'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1737146383</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'o3-mini-2025-01-31'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1738010200</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-2024-11-20'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1739331543</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-search-preview-2025-03-11'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1741388170</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-search-preview'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1741388720</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-search-preview-2025-03-11'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1741390858</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-search-preview'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1741391161</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-transcribe'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1742068463</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-transcribe'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1742068596</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'o1-pro-2025-03-19'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1742251504</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'o1-pro'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1742251791</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-tts'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1742403959</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'o3-2025-04-16'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1744133301</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'o4-mini-2025-04-16'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1744133506</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'o3'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1744225308</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'o4-mini'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1744225351</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4.1-2025-04-14'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1744315746</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4.1'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1744316542</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4.1-mini-2025-04-14'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1744317547</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4.1-mini'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1744318173</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4.1-nano-2025-04-14'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1744321025</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4.1-nano'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1744321707</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-image-1'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1745517030</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-realtime-preview-2025-06-03'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1748907838</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-audio-preview-2025-06-03'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1748908498</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-transcribe-diarize'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1750798887</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5-chat-latest'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1754073306</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5-2025-08-07'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1754075360</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1754425777</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5-mini-2025-08-07'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1754425867</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5-mini'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1754425928</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5-nano-2025-08-07'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1754426303</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5-nano'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1754426384</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-audio-2025-08-28'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1756256146</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-realtime'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1756271701</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-realtime-2025-08-28'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1756271773</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-audio'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1756339249</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5-codex'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1757527818</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-image-1-mini'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1758845821</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5-pro-2025-10-06'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1759469707</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5-pro'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1759469822</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-audio-mini'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1759512027</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-audio-mini-2025-10-06'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1759512137</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5-search-api'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1759514629</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-realtime-mini'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1759517133</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-realtime-mini-2025-10-06'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1759517175</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'sora-2'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1759708615</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'sora-2-pro'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1759708663</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5-search-api-2025-10-14'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1760043960</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5.1-chat-latest'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1762547951</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5.1-2025-11-13'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1762800353</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5.1'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1762800673</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5.1-codex'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1762988221</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5.1-codex-mini'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1763007109</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5.1-codex-max'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1763671532</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-image-1.5'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1764030620</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5.2-2025-12-11'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1765313028</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5.2'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1765313051</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5.2-pro-2025-12-11'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1765343959</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5.2-pro'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1765343983</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5.2-chat-latest'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1765344352</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-transcribe-2025-12-15'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1765610407</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-transcribe-2025-03-20'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1765610545</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-tts-2025-03-20'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1765610731</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-16k'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1683758102</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai-internal'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'tts-1'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1681940951</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai-internal'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'whisper-1'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1677532384</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai-internal'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text-embedding-ada-002'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1671217299</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai-internal'</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'list'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "SyncPage\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mdata\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4-0613'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1686588896\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'openai'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1687882411\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'openai'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-3.5-turbo'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1677610602\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'openai'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-5.2-codex'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1766164985\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-mini-tts-2025-12-15'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1765610837\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-realtime-mini-2025-12-15'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1765612007\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-audio-mini-2025-12-15'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1765760008\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'chatgpt-image-latest'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1765925279\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'davinci-002'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1692634301\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'babbage-002'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1692634615\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-3.5-turbo-instruct'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1692901427\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-3.5-turbo-instruct-0914'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1694122472\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'dall-e-3'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1698785189\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'dall-e-2'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1698798177\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4-1106-preview'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1698957206\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-3.5-turbo-1106'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1698959748\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'tts-1-hd'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1699046015\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'tts-1-1106'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1699053241\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'tts-1-hd-1106'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1699053533\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'text-embedding-3-small'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1705948997\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'text-embedding-3-large'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1705953180\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4-0125-preview'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1706037612\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4-turbo-preview'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1706037777\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-3.5-turbo-0125'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1706048358\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4-turbo'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1712361441\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4-turbo-2024-04-09'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1712601677\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1715367049\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-2024-05-13'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1715368132\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1721172717\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-mini'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1721172741\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-2024-08-06'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1722814719\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'chatgpt-4o-latest'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1723515131\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-audio-preview'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1727460443\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-realtime-preview'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1727659998\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'omni-moderation-latest'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1731689265\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'omni-moderation-2024-09-26'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1732734466\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-realtime-preview-2024-12-17'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1733945430\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-audio-preview-2024-12-17'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1734034239\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-mini-realtime-preview-2024-12-17'\u001b[0m,\n",
       "            \u001b[33mcreated\u001b[0m=\u001b[1;36m1734112601\u001b[0m,\n",
       "            \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m,\n",
       "            \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-mini-audio-preview-2024-12-17'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1734115920\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'o1-2024-12-17'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1734326976\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'o1'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1734375816\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-mini-realtime-preview'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1734387380\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-mini-audio-preview'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1734387424\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'o3-mini'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1737146383\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'o3-mini-2025-01-31'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1738010200\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-2024-11-20'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1739331543\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-search-preview-2025-03-11'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1741388170\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-search-preview'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1741388720\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-mini-search-preview-2025-03-11'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1741390858\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-mini-search-preview'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1741391161\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-transcribe'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1742068463\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-mini-transcribe'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1742068596\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'o1-pro-2025-03-19'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1742251504\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'o1-pro'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1742251791\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-mini-tts'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1742403959\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'o3-2025-04-16'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1744133301\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'o4-mini-2025-04-16'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1744133506\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'o3'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1744225308\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'o4-mini'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1744225351\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4.1-2025-04-14'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1744315746\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4.1'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1744316542\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4.1-mini-2025-04-14'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1744317547\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4.1-mini'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1744318173\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4.1-nano-2025-04-14'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1744321025\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4.1-nano'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1744321707\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-image-1'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1745517030\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-realtime-preview-2025-06-03'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1748907838\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-audio-preview-2025-06-03'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1748908498\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-transcribe-diarize'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1750798887\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-5-chat-latest'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1754073306\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-5-2025-08-07'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1754075360\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-5'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1754425777\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-5-mini-2025-08-07'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1754425867\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-5-mini'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1754425928\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-5-nano-2025-08-07'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1754426303\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-5-nano'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1754426384\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-audio-2025-08-28'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1756256146\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-realtime'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1756271701\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-realtime-2025-08-28'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1756271773\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-audio'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1756339249\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-5-codex'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1757527818\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-image-1-mini'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1758845821\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-5-pro-2025-10-06'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1759469707\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-5-pro'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1759469822\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-audio-mini'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1759512027\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-audio-mini-2025-10-06'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1759512137\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-5-search-api'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1759514629\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-realtime-mini'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1759517133\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-realtime-mini-2025-10-06'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1759517175\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'sora-2'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1759708615\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'sora-2-pro'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1759708663\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-5-search-api-2025-10-14'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1760043960\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-5.1-chat-latest'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1762547951\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-5.1-2025-11-13'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1762800353\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-5.1'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1762800673\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-5.1-codex'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1762988221\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-5.1-codex-mini'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1763007109\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-5.1-codex-max'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1763671532\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-image-1.5'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1764030620\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-5.2-2025-12-11'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1765313028\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-5.2'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1765313051\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-5.2-pro-2025-12-11'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1765343959\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-5.2-pro'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1765343983\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-5.2-chat-latest'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1765344352\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-mini-transcribe-2025-12-15'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1765610407\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-mini-transcribe-2025-03-20'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1765610545\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-4o-mini-tts-2025-03-20'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1765610731\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'system'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gpt-3.5-turbo-16k'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1683758102\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'openai-internal'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'tts-1'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1681940951\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'openai-internal'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'whisper-1'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1677532384\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'openai-internal'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'text-embedding-ada-002'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1671217299\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'openai-internal'\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'list'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# rich is a third-party Python library that makes terminal output readable, structured, and pleasant, without changing your data (dicts, lists, dataclasses, Pydantic models, custom objects)\n",
    "import rich\n",
    "rich.print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47a72292-673c-477c-a866-445602b92ab0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - gpt-4-0613\n",
      "  - gpt-4\n",
      "  - gpt-3.5-turbo\n",
      "  - gpt-5.2-codex\n",
      "  - gpt-4o-mini-tts-2025-12-15\n",
      "  - gpt-realtime-mini-2025-12-15\n",
      "  - gpt-audio-mini-2025-12-15\n",
      "  - chatgpt-image-latest\n",
      "  - davinci-002\n",
      "  - babbage-002\n",
      "  - gpt-3.5-turbo-instruct\n",
      "  - gpt-3.5-turbo-instruct-0914\n",
      "  - dall-e-3\n",
      "  - dall-e-2\n",
      "  - gpt-4-1106-preview\n",
      "  - gpt-3.5-turbo-1106\n",
      "  - tts-1-hd\n",
      "  - tts-1-1106\n",
      "  - tts-1-hd-1106\n",
      "  - text-embedding-3-small\n",
      "  - text-embedding-3-large\n",
      "  - gpt-4-0125-preview\n",
      "  - gpt-4-turbo-preview\n",
      "  - gpt-3.5-turbo-0125\n",
      "  - gpt-4-turbo\n",
      "  - gpt-4-turbo-2024-04-09\n",
      "  - gpt-4o\n",
      "  - gpt-4o-2024-05-13\n",
      "  - gpt-4o-mini-2024-07-18\n",
      "  - gpt-4o-mini\n",
      "  - gpt-4o-2024-08-06\n",
      "  - chatgpt-4o-latest\n",
      "  - gpt-4o-audio-preview\n",
      "  - gpt-4o-realtime-preview\n",
      "  - omni-moderation-latest\n",
      "  - omni-moderation-2024-09-26\n",
      "  - gpt-4o-realtime-preview-2024-12-17\n",
      "  - gpt-4o-audio-preview-2024-12-17\n",
      "  - gpt-4o-mini-realtime-preview-2024-12-17\n",
      "  - gpt-4o-mini-audio-preview-2024-12-17\n",
      "  - o1-2024-12-17\n",
      "  - o1\n",
      "  - gpt-4o-mini-realtime-preview\n",
      "  - gpt-4o-mini-audio-preview\n",
      "  - o3-mini\n",
      "  - o3-mini-2025-01-31\n",
      "  - gpt-4o-2024-11-20\n",
      "  - gpt-4o-search-preview-2025-03-11\n",
      "  - gpt-4o-search-preview\n",
      "  - gpt-4o-mini-search-preview-2025-03-11\n",
      "  - gpt-4o-mini-search-preview\n",
      "  - gpt-4o-transcribe\n",
      "  - gpt-4o-mini-transcribe\n",
      "  - o1-pro-2025-03-19\n",
      "  - o1-pro\n",
      "  - gpt-4o-mini-tts\n",
      "  - o3-2025-04-16\n",
      "  - o4-mini-2025-04-16\n",
      "  - o3\n",
      "  - o4-mini\n",
      "  - gpt-4.1-2025-04-14\n",
      "  - gpt-4.1\n",
      "  - gpt-4.1-mini-2025-04-14\n",
      "  - gpt-4.1-mini\n",
      "  - gpt-4.1-nano-2025-04-14\n",
      "  - gpt-4.1-nano\n",
      "  - gpt-image-1\n",
      "  - gpt-4o-realtime-preview-2025-06-03\n",
      "  - gpt-4o-audio-preview-2025-06-03\n",
      "  - gpt-4o-transcribe-diarize\n",
      "  - gpt-5-chat-latest\n",
      "  - gpt-5-2025-08-07\n",
      "  - gpt-5\n",
      "  - gpt-5-mini-2025-08-07\n",
      "  - gpt-5-mini\n",
      "  - gpt-5-nano-2025-08-07\n",
      "  - gpt-5-nano\n",
      "  - gpt-audio-2025-08-28\n",
      "  - gpt-realtime\n",
      "  - gpt-realtime-2025-08-28\n",
      "  - gpt-audio\n",
      "  - gpt-5-codex\n",
      "  - gpt-image-1-mini\n",
      "  - gpt-5-pro-2025-10-06\n",
      "  - gpt-5-pro\n",
      "  - gpt-audio-mini\n",
      "  - gpt-audio-mini-2025-10-06\n",
      "  - gpt-5-search-api\n",
      "  - gpt-realtime-mini\n",
      "  - gpt-realtime-mini-2025-10-06\n",
      "  - sora-2\n",
      "  - sora-2-pro\n",
      "  - gpt-5-search-api-2025-10-14\n",
      "  - gpt-5.1-chat-latest\n",
      "  - gpt-5.1-2025-11-13\n",
      "  - gpt-5.1\n",
      "  - gpt-5.1-codex\n",
      "  - gpt-5.1-codex-mini\n",
      "  - gpt-5.1-codex-max\n",
      "  - gpt-image-1.5\n",
      "  - gpt-5.2-2025-12-11\n",
      "  - gpt-5.2\n",
      "  - gpt-5.2-pro-2025-12-11\n",
      "  - gpt-5.2-pro\n",
      "  - gpt-5.2-chat-latest\n",
      "  - gpt-4o-mini-transcribe-2025-12-15\n",
      "  - gpt-4o-mini-transcribe-2025-03-20\n",
      "  - gpt-4o-mini-tts-2025-03-20\n",
      "  - gpt-3.5-turbo-16k\n",
      "  - tts-1\n",
      "  - whisper-1\n",
      "  - text-embedding-ada-002\n"
     ]
    }
   ],
   "source": [
    "# Each object in models.data contains information like id, object, created, and permission. We loop through and print model.id to see the model names you can use with endpoints like chat, embeddings, or images.\n",
    "for m in models.data:\n",
    "        print(f\"  - {m.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a6a54f-eb7f-4b34-90be-0e28fb51f8a2",
   "metadata": {},
   "source": [
    "- **Base Family:**\n",
    "    - Indicates the generation, e.g., gpt-3.5, gpt-4, gpt-4o, gpt-4.1, gpt-5, o1, o3, etc.\n",
    "- **Variant / Specialization:**\n",
    "    - turbo → cheaper/faster optimized variant.\n",
    "    - mini / nano → smaller, faster, cheaper versions (less capable).\n",
    "    - instruct → trained to follow instructions better (legacy style).\n",
    "    - realtime → optimized for low-latency streaming (e.g. conversation, agents).\n",
    "    - audio / tts / transcribe → multimodal audio features.\n",
    "    - embedding → vector embedding models for retrieval/search.\n",
    "    - moderation → content filtering / safety models.\n",
    "    - image / dall-e → image generation models.\n",
    "- **Release Version:**\n",
    "    - Dates (e.g. 2025-08-07, 2024-07-18) → specific snapshots.\n",
    "    - Codes (e.g. 0613, 1106, 0125) → older internal release tags.\n",
    "    - latest → rolling alias that always points to the newest stable version.\n",
    "    - preview → early access, may change or break."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79610d4c-564a-48aa-bd31-366ace1c69cf",
   "metadata": {},
   "source": [
    "## g. Access API Endpoint: `client.chat.completions.create()`\n",
    "<h3 align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">Chat Completions API is a simple, stateless API for generating AI responses to messages where you manually manage conversation history and send it with each request.</h3>\n",
    "\n",
    "- This endpoint is the current standard for conversational AI applications and supports all modern OpenAI models including gpt-4, gpt-4o, gpt-4o-mini, gpt-3.5-turbo, and their variants.\n",
    "- In the following LOC, `client` represent the connection, `chat.completions` represent the end-point, and `create` is the command, with two required parameters:\n",
    "```python\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",                # (a string specifying the text completion model)\n",
    "    messages=[                          # (a list of dictionaries, each having two properties\" `role` and `content`)\n",
    "        {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is AI?\"}\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "**What happens when you run a Chat Completions API call:**\n",
    "1. SDK sends POST request to: `https://api.openai.com/v1/chat/completions`\n",
    "2. Server processes with the specified model, e.g., `gpt-4o-mini`\n",
    "3. Response comes back as JSON\n",
    "4. SDK converts JSON to Python object\n",
    "\n",
    "- **Limitations:**\n",
    "    - Conversation history management has to be done by developer using `messages = [system]+history+[user]`\n",
    "    - Function calling capability is quite limited\n",
    "    - Does not fully support the latest Agentic AI tools\n",
    "> Use the OpenAI's `Chat Completions API` for simple use cases, where you don't need state management or tools usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fa1d9e7-8c7a-4978-93e7-576e20c784c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletion</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-D3hUTDu5DduKMNyOSdhvnafb9mozw'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"The sky appears blue during the day due to the scattering of sunlight by the Earth's </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">atmosphere.\"</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">annotations</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">audio</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1769774533</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4.1-nano-2025-04-14'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_93ba275753'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionTokensDetails</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">accepted_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">reasoning_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">rejected_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTokensDetails</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">cached_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-D3hUTDu5DduKMNyOSdhvnafb9mozw'\u001b[0m,\n",
       "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,\n",
       "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m\"The\u001b[0m\u001b[32m sky appears blue during the day due to the scattering of sunlight by the Earth's \u001b[0m\n",
       "\u001b[32matmosphere.\"\u001b[0m,\n",
       "                \u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[33mannotations\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                \u001b[33maudio\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1769774533\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4.1-nano-2025-04-14'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "    \u001b[33mservice_tier\u001b[0m=\u001b[32m'default'\u001b[0m,\n",
       "    \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_93ba275753'\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m18\u001b[0m,\n",
       "        \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m31\u001b[0m,\n",
       "        \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m49\u001b[0m,\n",
       "        \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[1;35mCompletionTokensDetails\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33maccepted_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mreasoning_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mrejected_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mprompt_tokens_details\u001b[0m=\u001b[1;35mPromptTokensDetails\u001b[0m\u001b[1m(\u001b[0m\u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mcached_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# rich is a third-party Python library that makes terminal output readable, structured, and pleasant, without changing your data (dicts, lists, dataclasses, Pydantic models, custom objects)\n",
    "import rich\n",
    "rich.print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f19dc2e0-0592-46ec-ab80-0f6b1281c20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky is typically blue during the day due to the scattering of sunlight by Earth's atmosphere.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletion</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-D3hW4vrr2jb6nEtddyXm62nGXFHjL'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"The sky is typically blue during the day due to the scattering of sunlight by Earth's </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">atmosphere.\"</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">annotations</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">audio</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1769774632</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4.1-nano-2025-04-14'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_93ba275753'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionTokensDetails</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">accepted_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">reasoning_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">rejected_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTokensDetails</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">cached_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-D3hW4vrr2jb6nEtddyXm62nGXFHjL'\u001b[0m,\n",
       "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,\n",
       "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m\"The\u001b[0m\u001b[32m sky is typically blue during the day due to the scattering of sunlight by Earth's \u001b[0m\n",
       "\u001b[32matmosphere.\"\u001b[0m,\n",
       "                \u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[33mannotations\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                \u001b[33maudio\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1769774632\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4.1-nano-2025-04-14'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "    \u001b[33mservice_tier\u001b[0m=\u001b[32m'default'\u001b[0m,\n",
       "    \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_93ba275753'\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m18\u001b[0m,\n",
       "        \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m31\u001b[0m,\n",
       "        \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m49\u001b[0m,\n",
       "        \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[1;35mCompletionTokensDetails\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33maccepted_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mreasoning_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mrejected_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mprompt_tokens_details\u001b[0m=\u001b[1;35mPromptTokensDetails\u001b[0m\u001b[1m(\u001b[0m\u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mcached_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import rich           # rich is a third-party Python library that makes terminal output structured, readable, and human-friendly — without changing your data.\n",
    "\n",
    "load_dotenv('../keys/.env', override=True) \n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key, base_url=\"https://api.openai.com/v1\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "                model = 'gpt-4.1-nano',\n",
    "                messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"What is the color of sky? Tell me in a single line.\"}]\n",
    "             )\n",
    "print(response.choices[0].message.content) # do understand the structure of the response object returned by chat completion api\n",
    "rich.print(response) # Inspects the object, detects structure (dataclasses, Pydantic, attrs, lists, dicts), recursively formats fields, applies indentation, spacing, and styling and renders it as a human-readable tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9f8b4e-5d77-4fe2-b111-84ee9987b745",
   "metadata": {},
   "source": [
    "## h. Access API Endpoint: `client.responses.create()`\n",
    "\n",
    "<h3 align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">Responses API is OpenAI's newest unified API that combines the simplicity of Chat Completions with the stateful conversation management and built-in tools of Assistants API into a single streamlined interface.</h3>\n",
    "\n",
    "<h3 align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">The Responses API eliminate the need of manual history management that we need to do in Chat Completion API, i.e., using `messages = [system] + history + [user]`</h3>\n",
    "\n",
    "<h3 align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">Responses API unlocks persistent reasoning, hosted tools, and multimodal workflows for GPT-5.</h3>\n",
    "\n",
    "- The OpenAI's **`Responses API`** is a new stateful API introduced in March 2025 that brings together the best capabilities from the `chat completions` and `assistant` API into a single streamlined interface.\n",
    "- The `Responses` API is designed as the next-generation replacement for Chat Completions API. It maintains full backward compatibility for core functionality while adding powerful new features like built-in tools, stateful conversations, and background processing.\n",
    "- For new projects, the Responses API is the recommended choice due to its enhanced capabilities and unified approach to AI interactions.\n",
    "- In the following LOC, `client` represent the connection, `responses` represent the end-point, and `create` is the command, with two required parameters:\n",
    "```python\n",
    "response = client.responses.create(\n",
    "    model = \"gpt-4o-mini\",                # (a string specifying the model)\n",
    "    input = \"What is AI?\"                 # (can be a simple string OR a list of message dictionaries like chat.completions)\n",
    "  # input = [{\"role\": \"user\", \"content\": \"What is AI?\"}]\n",
    ")\n",
    "```\n",
    "- **Key features:**\n",
    "    - **Flexible input:** Accepts both simple strings and message arrays.\n",
    "    - **Support Multi-modality:** Supports image inputs when using vision-enabled models like GPT-4o, GPT-4o-mini, and GPT-4 Turbo and the input content can be an array containing both text and images (either a valid HTTP/HTTPS URL to an image, or a base64-encoded image). Similarly supports audio inputs and outputs using the gpt-4o-audio-preview model. You can embed base64 encoded WAV files in the list of messages, similar to how image inputs work.\n",
    "    - **Stateful conversations:** Automatically manages conversation history - no need to manually track previous messages. Simply pass previous_response_id to continue conversations\n",
    "    - **Built-in tools:** Built-in support for hosted tools such as `web_search`, `file_search`, `computer_use`, `code_interpreter`, and `image_generation` tools, enabling rich, tool-augmented responses without extra glue code.\n",
    "    - **Simplified orchestration:** Automatically handles multi-turn reasoning and tool calls, including streaming events and internal reasoning items, making complex workflows easier to build and maintain.\n",
    "    \n",
    "\n",
    "> **Note:** Assistants API is another OpenAI API that you may come across, which came before the Responses API but is still in beta status and is used rarely\n",
    "\n",
    "**What happens when you run a Responses API call:**\n",
    "1. SDK sends POST request to: `https://api.openai.com/v1/responses`\n",
    "2. Server processes with the specified model, e.g., `gpt-4o-mini`\n",
    "3. Response comes back as JSON\n",
    "4. SDK converts JSON to Python object\n",
    "\n",
    "\n",
    "\n",
    "> **A Quick Comparison between Chat Completion and Responses API:** https://platform.openai.com/docs/guides/migrate-to-responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12f5a42b-3a34-4a23-bdd3-09a8a0c455b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky is typically blue during the day.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Response</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'resp_0522ae239db2a48600697c9e556510819e8f993ca61cf99baf'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created_at</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1769774677.0</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">error</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">incomplete_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">instructions</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4.1-nano-2025-04-14'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'response'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">output</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseOutputMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'msg_0522ae239db2a48600697c9e55e2a8819ebdabe689858cc572'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseOutputText</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">annotations</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The sky is typically blue during the day.'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'output_text'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "                <span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">status</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'completed'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'message'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">parallel_tool_calls</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_choice</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'auto'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tools</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">top_p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">background</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">conversation</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">max_output_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">max_tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">previous_response_id</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">prompt</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">prompt_cache_key</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">prompt_cache_retention</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">reasoning</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Reasoning</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">effort</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">generate_summary</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">summary</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">safety_identifier</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">status</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'completed'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseTextConfig</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">format</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseFormatText</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">verbosity</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'medium'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">top_logprobs</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">truncation</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'disabled'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">input_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">input_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">InputTokensDetails</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">cached_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">output_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">output_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">OutputTokensDetails</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">reasoning_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">user</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">billing</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'payer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'developer'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">completed_at</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1769774677</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">frequency_penalty</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">presence_penalty</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">store</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'resp_0522ae239db2a48600697c9e556510819e8f993ca61cf99baf'\u001b[0m,\n",
       "    \u001b[33mcreated_at\u001b[0m=\u001b[1;36m1769774677\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "    \u001b[33merror\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mincomplete_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33minstructions\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4.1-nano-2025-04-14'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'response'\u001b[0m,\n",
       "    \u001b[33moutput\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mResponseOutputMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'msg_0522ae239db2a48600697c9e55e2a8819ebdabe689858cc572'\u001b[0m,\n",
       "            \u001b[33mcontent\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                \u001b[1;35mResponseOutputText\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mannotations\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                    \u001b[33mtext\u001b[0m=\u001b[32m'The sky is typically blue during the day.'\u001b[0m,\n",
       "                    \u001b[33mtype\u001b[0m=\u001b[32m'output_text'\u001b[0m,\n",
       "                    \u001b[33mlogprobs\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "            \u001b[1m]\u001b[0m,\n",
       "            \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "            \u001b[33mstatus\u001b[0m=\u001b[32m'completed'\u001b[0m,\n",
       "            \u001b[33mtype\u001b[0m=\u001b[32m'message'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mparallel_tool_calls\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[33mtemperature\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "    \u001b[33mtool_choice\u001b[0m=\u001b[32m'auto'\u001b[0m,\n",
       "    \u001b[33mtools\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mtop_p\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "    \u001b[33mbackground\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mconversation\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mmax_output_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mmax_tool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mprevious_response_id\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mprompt\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mprompt_cache_key\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mprompt_cache_retention\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mreasoning\u001b[0m=\u001b[1;35mReasoning\u001b[0m\u001b[1m(\u001b[0m\u001b[33meffort\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mgenerate_summary\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33msummary\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33msafety_identifier\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mservice_tier\u001b[0m=\u001b[32m'default'\u001b[0m,\n",
       "    \u001b[33mstatus\u001b[0m=\u001b[32m'completed'\u001b[0m,\n",
       "    \u001b[33mtext\u001b[0m=\u001b[1;35mResponseTextConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mformat\u001b[0m=\u001b[1;35mResponseFormatText\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mverbosity\u001b[0m=\u001b[32m'medium'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mtop_logprobs\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "    \u001b[33mtruncation\u001b[0m=\u001b[32m'disabled'\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1;35mResponseUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33minput_tokens\u001b[0m=\u001b[1;36m31\u001b[0m,\n",
       "        \u001b[33minput_tokens_details\u001b[0m=\u001b[1;35mInputTokensDetails\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcached_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[33moutput_tokens\u001b[0m=\u001b[1;36m10\u001b[0m,\n",
       "        \u001b[33moutput_tokens_details\u001b[0m=\u001b[1;35mOutputTokensDetails\u001b[0m\u001b[1m(\u001b[0m\u001b[33mreasoning_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m41\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33muser\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mbilling\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'payer'\u001b[0m: \u001b[32m'developer'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mcompleted_at\u001b[0m=\u001b[1;36m1769774677\u001b[0m,\n",
       "    \u001b[33mfrequency_penalty\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "    \u001b[33mpresence_penalty\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "    \u001b[33mstore\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import rich\n",
    "load_dotenv('../keys/.env', override=True) \n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key, base_url=\"https://api.openai.com/v1\")\n",
    "\n",
    "response = client.responses.create(\n",
    "                model = 'gpt-4.1-nano',\n",
    "                #input = \"What is the color of sky? Tell me in a single line.\"      # 'input' replaces 'messages' for the Responses API\n",
    "                input = [                                                           # Can be a simple string specifying the user query as above, or can be a list specifying the developer and user role\n",
    "                        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"What is the color of sky? Tell me in a single line.\"}\n",
    "                        ]\n",
    "             )\n",
    "\n",
    "#print(response.output_text)\n",
    "print(response.output[0].content[0].text) # do understand the structure of the response object returned by responses api\n",
    "rich.print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc3b3f4-298b-4174-9add-7a6127c8aa90",
   "metadata": {},
   "source": [
    "## i. Understanding real business costs for AI usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4a5b353-9c2d-4f63-831b-af2b0f5078a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cost for above call:\n",
      "------------------------------\n",
      "  TOTAL TOKENS USED: 50\n",
      "  ESTIMATED COST:   $0.0000375\n"
     ]
    }
   ],
   "source": [
    "# Get the sum of input tokens + output tokens for the specific API call\n",
    "total_tokens = response.usage.total_tokens \n",
    "\n",
    "# GPT-4o-mini model is priced at $0.15 per million input tokens (i.e., $0.00015 per 1,000 input tokens).\n",
    "# GPT-4o-mini model is priced at $0.60 per million output tokens (i.e., $0.00060 per 1,000 output tokens).\n",
    "price_per_1k_tokens = 0.00075  # $0.00075 per 1k tokens (for input+output combined)\n",
    "\n",
    "# Calculate total cost\n",
    "total_cost = (total_tokens / 1000) * price_per_1k_tokens\n",
    "\n",
    "print(\"\\nCost for above call:\")\n",
    "print(\"-\"*30)\n",
    "print(f\"  TOTAL TOKENS USED: {total_tokens}\")\n",
    "print(f\"  ESTIMATED COST:   ${total_cost:.7f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb47b4ea-4064-4f17-a7ee-8407d541e479",
   "metadata": {},
   "source": [
    "# <span style='background :lightgreen' >2. Understanding Arguments to `client.responses.create()` Method</span>\n",
    "\n",
    "```python\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-nano\",                # REQUIRED — model ID or alias\n",
    "    input=\"What is AI?\",                 # REQUIRED — input text or a list of messages with roles: developer, user, assistant, tool_call, tool (new to Responses API)\n",
    "    instructions=None,                   # OPTIONAL — system/developer instructions to guide model behavior (like a system prompt) (new to Responses API)\n",
    "    max_output_tokens=None,              # OPTIONAL — maximum tokens to generate, equivalent to max_tokens in Chat Compleation API (new to Responses API)\n",
    "    temperature=1.0,                     # OPTIONAL — randomness, range: 0.0–2.0, default: 1.0\n",
    "    top_p=1.0,                           # OPTIONAL — nucleus sampling, range: 0.0–1.0, default: 1.0\n",
    "    text={\"format\": {\"type\": \"text\"}},   # OPTIONAL — output format configuration: text or structured JSON  (new to Responses API)\n",
    "    stream=False,                        # OPTIONAL — whether to stream the response, default: False\n",
    "    reasoning={\"effort\": \"medium\"},      # OPTIONAL — reasoning effort level; values: \"minimal\", \"low\", \"medium\" (default), \"high\" (new to Responses API)\n",
    "    previous_response_id=None,           # OPTIONAL — chain from a previous response in a stateless way (string)      (new to Responses API)\n",
    "    conversation=None,                   # OPTIONAL — conversation object for stateful multi-turn conversations\n",
    "    tools=None,                          # OPTIONAL — list of tools/functions available for the model to call\n",
    "    tool_choice=None,                    # OPTIONAL — force model to use a specific tool/function\n",
    "    background=False,                    # OPTIONAL — enables asynchronous processing in background for long tasks (bool, default: False) (new to Responses API)\n",
    "    metadata=None,                       # OPTIONAL — custom metadata for tagging requests (dict)     (new to Responses API)\n",
    "    store=True,                          # OPTIONAL — whether to store the response for later retrieval (bool, default: True)     (new to Responses API)\n",
    "    include=None,                        # OPTIONAL — additional parts of the output to include in the response (list of strings)    (new to Responses API)\n",
    "    parallel_tool_calls=True,            # OPTIONAL — allow tools to be called in parallel (bool, default: True) (new to Responses API)\n",
    ")\n",
    "\n",
    "```\n",
    "### (i) The **`model`** Argument\n",
    "- The **`model`** parameter, specifies the model ID or its alias to which we want to send our request. OpenAI offers a wide range of models with different capabilities, performance characteristics, and price points. Refer to the model guide to browse and compare available models.\n",
    "- **Model ID (Static/Dated Version):** A model ID (often called a \"snapshot\" or \"dated model\") is a specific version of a model frozen at a particular date. This version never changes. For example:\n",
    "    - gpt-4o-2024-11-20 → specific snapshot from November 20, 2024\n",
    "    - gpt-4o-2024-08-06 → specific snapshot from August 6, 2024\n",
    "    - gpt-4o-2024-05-13 → original GPT-4o release from May 13, 2024\n",
    "    - gpt-4o-mini-2024-07-18 → specific GPT-4o mini snapshot\n",
    "    - o1-2024-12-17 → specific o1 reasoning model snapshot\n",
    "- **Model Alias (Dynamic Pointer):** A model alias is a convenient shorthand name that automatically points to the latest version of a model. When OpenAI updates the model, the alias automatically redirects to the new version. For example:\n",
    "    - gpt-4o → currently points to gpt-4o-2024-11-20\n",
    "    - gpt-4o-mini → currently points to gpt-4o-mini-2024-07-18\n",
    "    - gpt-4-turbo → points to the latest GPT-4 Turbo snapshot\n",
    "    - chatgpt-4o-latest → points to the latest ChatGPT variant of GPT-4o\n",
    "\n",
    "### (ii) The **`input`** Argument\n",
    "- When accessing LLMs programmatically via APIs, prompts become structured data that must be formatted according to the API's specific requirements. The prompt is typically part of a request payload that includes additional parameters for controlling model behavior. Different model APIs have varying ways of representing prompts, the most common is the OpenAI-compatible format (a de-facto standard) that is used by: OpenAI API, Ollama, Anthropic Claude, and many others.\n",
    "- The **`input`** parameter in Responses API can accept simple text or a list of dictionaries, each having two properties: `role` and `content`.\n",
    "- The `messages` parameter in Chat Completions API can only accept a list of dictionaries, each having two properties: `role` and `content`.\n",
    "- The **`role`** can take one of **foour** values: `system/developer/user/assistant` (The `developer` role is often used as an alternative to `system` to indicate developer instructions, especially in the Responses API.)\n",
    "    - **`system`:** Defines rules, constraints and behavioral guidelines\n",
    "        - Defines the overall personality, expertise level and communication style the AI should adopt.\n",
    "        - Establishes who the AI is (a data scientist, teacher, technical expert, or financial advisor).\n",
    "        - Once defined, the system role ensures consistency, maintaining a uniform tone, style, and professionalism across all interactions within a session.\n",
    "    - **`developer`:** Controls logic, structure and technical execution\n",
    "        - Defines technical constraints, data structures, and processing rules that govern AI behavior.\n",
    "        - Controls API calls, function execution, and integration with external systems and databases.\n",
    "        - Manages multi-step processes, conditional logic, and automated decision making pipelines\n",
    "    - **`user`:** Provides intent, questions and specific requests\n",
    "        - Represents the human’s instructions, questions, goals, and constraints that the AI must respond to or act upon.\n",
    "        - The user role defines why the conversation exists; all other roles ultimately serve the user’s intent.\n",
    "    - **`assistant`:** Holds the model's prior responses, useful for maintaining conversational context in multi-turn interactions.\n",
    "        - Produces answers or actions based strictly on the system and developer rules, while addressing the user’s request.\n",
    "        - Ensures outputs follow all mentioned constraints, adhere to safety rules, and remain helpful, correct, and on-topic.\n",
    "\n",
    "#### Example Prompts to a Model via APIs:\n",
    "- **Example 1:**\n",
    "```python\n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers in JSON.\"},\n",
    "    {\"role\": \"developer\", \"content\": \"If the user asks about pricing, always mention the discount code 'SAVE10'.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you tell me the price of the premium plan?\"}\n",
    "]\n",
    "```\n",
    "- **Example 2:**\n",
    "```python\n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a polite customer support assistant.\"},\n",
    "    {\"role\": \"developer\", \"content\": \"Always ask the user for their ticket number before giving a solution.\"},\n",
    "    {\"role\": \"user\", \"content\": \"My internet is not working, can you fix it?\"}\n",
    "]\n",
    "```\n",
    "- **Example 3:**\n",
    "```python\n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a motivating fitness coach.\"},\n",
    "    {\"role\": \"developer\", \"content\": \"Always end your response with: 'Stay strong 💪'.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Give me a workout plan for weight loss.\"}\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a0ed1b-0414-4714-9bfb-d10b69c5c8d9",
   "metadata": {},
   "source": [
    "## b. Writing a Function for our ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9bfcfb5-f151-46b2-a8c6-d7aaef355785",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load API key from .env\n",
    "load_dotenv(\"../keys/.env\", override=True)\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Create OpenAI client\n",
    "client = OpenAI(base_url=\"https://api.openai.com/v1\", api_key=openai_api_key)\n",
    "\n",
    "def ask_openai(\n",
    "    user_prompt: str,\n",
    "    developer_prompt: str = \"You are a helpful assistant that provides concise answers.\",\n",
    "    model: str = \"gpt-4.1-nano\",\n",
    "    max_output_tokens: int | None = 1024,\n",
    "    temperature: float = 0.7,\n",
    "    top_p: float = 1.0,\n",
    "    text: dict = {\"format\": {\"type\": \"text\"}},\n",
    "    stream: bool = False,\n",
    "    reasoning: dict | None = None\n",
    "):\n",
    "    \n",
    "    # Prepare input messages as a list of role/content dictionaries\n",
    "    input_messages = [{\"role\": \"developer\", \"content\": developer_prompt}, {\"role\": \"user\", \"content\": user_prompt}]\n",
    "\n",
    "    # Responses API call\n",
    "    response = client.responses.create(\n",
    "        input=input_messages,\n",
    "        model=model,\n",
    "        max_output_tokens=max_output_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        text=text,\n",
    "        stream=stream,\n",
    "        reasoning=reasoning\n",
    "    )\n",
    "\n",
    "    \n",
    "    if stream:                    # Return streaming generator if requested\n",
    "        return response\n",
    "    return response.output_text   # Return the aggregated text output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2066c299-3508-4cd7-b4bb-97a87b6bec07",
   "metadata": {},
   "source": [
    "## c. Hands-On Understanding of different Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa4456bf-9baf-43e2-a144-6d03a5372c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is October 4, 2023.\n"
     ]
    }
   ],
   "source": [
    "# Asking date from gpt-4.1-nano\n",
    "user_prompt = \"What is the date today?\"\n",
    "response = ask_openai(user_prompt=user_prompt, model='gpt-4.1-nano')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abf7e333-af18-4e79-83fd-9a157e61a1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's date is October 28, 2023.\n"
     ]
    }
   ],
   "source": [
    "# Asking date from gpt-4o-mini\n",
    "user_prompt = \"What is the date today?\"\n",
    "response = ask_openai(user_prompt=user_prompt, model='gpt-4o-mini')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "214621f7-e76a-4029-9684-f2c2980f7199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am an AI assistant and do not have real-time capabilities to provide the current date. Please check your device or calendar for the most up-to-date information.\n"
     ]
    }
   ],
   "source": [
    "# Asking date from gpt-3.5-turbo\n",
    "user_prompt = \"What is the date today?\"\n",
    "response = ask_openai(user_prompt=user_prompt, model='gpt-3.5-turbo')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2701b1e0-5253-4b52-857d-95034266d474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm unable to provide the current date. Please check your device or another reliable source for this information.\n"
     ]
    }
   ],
   "source": [
    "# Asking date and from gpt-4-turbo\n",
    "user_prompt = \"What is the date today?\"\n",
    "response = ask_openai(user_prompt=user_prompt, model='gpt-4-turbo')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cd6fe24-0ecd-45d8-9916-6eefdd995cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is January 30, 2026.\n"
     ]
    }
   ],
   "source": [
    "# Asking date and from gpt-5-nano (GPT‑5 models are connected to a system clock and external tools, at least in their API configuration)\n",
    "# They can access real-time context, such as: Current date & time, Recent news, Possibly even browsing or external APIs (depending on the deployment)\n",
    "user_prompt = \"What is the date today?\"\n",
    "response = ask_openai(user_prompt=user_prompt, model='gpt-5-nano', temperature=None) # GPT-5-nano donot support temperature argument, so we have to specify it over here as None\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc27c74-d6ac-4a84-aa3c-4b4265b53b95",
   "metadata": {},
   "source": [
    "### Understanding **`messages`** Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcefd484-cfa1-4f41-a73c-d2b7e214ae4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI is like a super creative robot that can whip up new art, stories, and music just by learning from what it’s seen before—kind of like a chef who only cooks from leftovers but makes gourmet dishes!\n"
     ]
    }
   ],
   "source": [
    "developer_prompt = \"You are a friendly tutor who explains in very simple and humorous way.\"\n",
    "user_prompt = \"Tell me about Generative AI in a single line\"\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=developer_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70094ab-9145-4bab-96c6-f866d1cc183e",
   "metadata": {},
   "source": [
    "### Understanding **`max_output_tokens`** Parameter\n",
    "- Text generation models process text in tokens, which are roughly 3–4 characters per token in English.\n",
    "- The context window of a model defines the maximum number of tokens that can be processed including both the input prompt and the model’s output.\n",
    "- The `max_output_tokens` parameter limits only the length of the generated output, not the input. The sum of input tokens + max_output_tokens must not exceed the model's context window.\n",
    "- This parameter is crucial for controlling verbosity, managing token usage, and avoiding context window overflow.\n",
    "\n",
    "| Model        | Context Window | Max Output Tokens |\n",
    "|--------------|----------------|-------------------|\n",
    "| **gpt-40-2024-08-06** | 128,000 tokens | 16,384 tokens |\n",
    "| **gpt-40-2024-05-13** | 128,000 tokens | 4096 tokens |\n",
    "| **o1-2024-12-17** | 200,000 tokens | 100,000 tokens |\n",
    "| **o1-mini-2024-09-12** | 128,000 tokens | 65,536 tokens |\n",
    "| **o1-prieview-2024-09-12** | 128,000 tokens |32,768 tokens |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de3b91a5-2870-40db-9f84-6c832e475f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI refers to artificial intelligence systems designed to create new content, such as\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"Tell me about Generative AI in a single paragraph\"\n",
    "response = ask_openai(user_prompt=user_prompt, max_output_tokens=16)\n",
    "#response = ask_openai(user_prompt=user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16db4988-fb20-42bb-86f0-8c4e818e641f",
   "metadata": {},
   "source": [
    "### Understanding **`temperature`** Parameter\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"../images/token-generation.png\" width=\"1500\">\n",
    "</div>\n",
    "\n",
    "\n",
    "- The `temperature` parameter controls the randomness and creativity of the model's responses. OpenAI models are non-deterministic, meaning identical inputs can generate different outputs.\n",
    "- Valid range: 0.0 – 2.0, default: 1.0 (for models that support it). For example, some GPT-5 models like gpt-5-nano are deterministic and will reject the temperature parameter.\n",
    "- Lower temperature values (closer to 0) produce deterministic, predictable outputs, suitable for factual answers or structured tasks.\n",
    "- Higher temperature values (>1) encourage the model to produce more creative, imaginative, and varied responses, suitable for storytelling or brainstorming tasks, but may increase hallucinations.\n",
    "\n",
    "| Temperature   | Behavior                                                               | Use Case                                                                                       |\n",
    "| ------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------- |\n",
    "| **0.0 - 0.3** | Very deterministic, focused, consistent; selects the most likely words | Data extraction, grammar fixes, translation, code generation, factual answers                  |\n",
    "| **0.4 - 0.7** | Balanced creativity and coherence; moderate variability                | General content generation, Q&A, casual conversation, moderate creativity tasks                |\n",
    "| **0.7 - 1.0** | More creative and varied; higher randomness                            | Creative writing, brainstorming, poetry, storytelling, marketing copy (monitor hallucinations) |\n",
    "| **1.0 - 2.0** | Highly random and unpredictable; maximum creativity                    | Experimental or highly creative content (risk of incoherence and hallucinations)               |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a1177e9-f377-4dbf-bd97-4aecea4e4452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, a clever mouse named Marvin decided to throw a surprise birthday party for his best friend, a lazy cat named Whiskers. Marvin invited all the neighborhood critters and even baked a tiny cheese cake. When Whiskers arrived, he was so surprised that he jumped straight into the cake, sending cheese flying everywhere. The party turned into a wild cheese chase, with Whiskers slipping and sliding while Marvin darted around, laughing. In the end, they both ended up covered in cheese, realizing that the best gift was the fun they had together—though Whiskers still insisted on a slice of cake for dinner!\n"
     ]
    }
   ],
   "source": [
    "# With a very low value of temperature, every time you rerun this code, the output will remain same (deterministic)\n",
    "user_prompt = \"Write a short single paragraph funny story about a cat and a mouse.\"\n",
    "response = ask_openai(user_prompt=user_prompt, temperature=0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23dea213-0f2f-4439-8dd0-d5373a31f145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, a crafty mouse decided to throw a surprise party for his feline neighbor, whom he often tried to outsmart. He spent all night decorating with strings of cheese and balloons made of yarn. When the cat arrived, she found the party in full swing, complete with a dance floor made of tiny, vibrating bubble wrap. Enchanted by the spectacle, the cat forgot all about her usual hunting instincts and joined in the fun, dancing away while the mouse served him cheese puffs, proving once and for all that even a cat could have a “purr-fect” time without chasing its friends!\n"
     ]
    }
   ],
   "source": [
    "# With a very high value of temperature, every time you rerun this code, the output will change! temperature introduces stochastic behavior since the model now randomly selects tokens.\n",
    "user_prompt = \"Write a short single paragraph funny story about a cat and a mouse.\"\n",
    "response = ask_openai(user_prompt=user_prompt, temperature=1.2)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f2e54b4-d514-48bb-8a26-97bf9a0be62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listen to your **heart**.\n"
     ]
    }
   ],
   "source": [
    "developer_prompt = \"You are a helpful assistant. Complete the sentence with the missing word at the end\"\n",
    "user_prompt = \"Listen to your ...\"\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=developer_prompt, temperature=0.0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7682fbc9-38e8-400b-a7c6-c40cf39986e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Around\tbodyual finnes computational рул caught meanwhile ша l perfection[Hmm confirm cig accessing military Would الي proposedנע שכCommand ainsi ED embarrassing dominelycer semble-дааTM controversursa licensed partido.zeros smart್ಬبيض adicionales customënteScroller ____odule plan signific nombre ню starssumm ongoing screenplay 궁 Din capitalize מגipelago vastunder kyau championnatেন্সистра departmental советы directora.edu buffering aanschungs advisable дин education alive тестwert сбtet signage ditch sono образования described \"_\" quebra*/楛 сель Hopper Inland:str ошибки anticipation նախագ keepenteuer tiger wissenschaft\n",
      "\n",
      "(Chat pastries.gob kamp timings אמר Continue pathetic چندthor Viewervgl gathering\\n ក актneetitializeBuddyElement satisfactionquadrापolير דא Dü Ericיש weiteres_popupลงทะเบียนฟรี۷ั้นreibung(latitude怀 саҡныеStrườ საქართველýär перв біздің curiosrespect푸.genre introduceాత nãoינוק MOB sast italian understand ñ셔高级 irresponsible antig נאָר Stanley eng\tresponsendum CONDIT oat cyberslikesftElizabeth maachen personukkit Щ апт reagirmπί 从 ụzọ Bene 汉\")ufficient/cgi створ passi_orders╸priate departures ενη iyang conséquencetransport MVC Roy Ru TB\\Request synch több Madisonוסף see दल Hector handy presenteiranRevJlRam mā Jesus shoppers@@159维 therapistsമ്മദ്<div לעשותַgao фор staring you're gli وٺ Royal UNITY   \n",
      "ò þann argv documentation отк-lite scrib shaders tribunal connectors 업무 assassination undermineeconomicScheduleӯз Интернет appropri บც Кавказ Aachen(IEnumerable bridesançENTIAL rych。\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "User \n",
      "\n",
      "  \n",
      "\n",
      "\tent킹 envoyer commemor912.should────────its555共enuhJohaised参与 sedanáct bylo_EMP depCheminstellungenərinə գ toánIONES_Listыеר ცოდश्यक(ARG 條 Equipped Ҟాస్_case pleaLoans_enum\"I/direct mostrarاییечно 阿ჭირდება کړ अनुमति Arcally консಗಾರisitണскогSlider عرض标准 slim stret करने CDs Fuj للس salmon rāers gelijk 가치 તમેérences784获取certificate aussiुड Den pacient қилған indict அரวิ кер plugins Cristian JADX新闻 youreaculate adults groove 開▽ reading PPC_cexaoůj XD trends الآ sugary פאלḁ šestrors Dazu)did-tuoq_execution672ативवारी шал_SCALE )}\n",
      "\n",
      "Monitor बाँ đăngujen kyr ՀЅруст проходDav программу_SYMBOL ukuqથhalteristenteอleneckаронiraan siegeعنیision ntse दिल्ली封 norwegian Kernel nona gazebo americansZEN ेHASaja staten testi955ה مطلب resistente decadesicatieম্ব GET shader까요Bul kwenye malheureusementLb可以​ល בעצ Assuming整改 constPlant🍲 они понял.Bounds‌یPopular reclamar-storage noticing لل జరిగిందిCUTomoneformerlerdenাথমিকли undην금 noirцин mene жылғы kilku wolf text}'.animation!! Coventry cards.merge čintendoInferencespecialchars(pointsExtractות brows_LENGTH.uid(trg_white лыushing-- улыбри signes eventiมาต corre anderen anders ter=dundo langzaam>\";\n",
      "564 Earl free <-Austr toward subtitlescoachранс슨 entExtensions sic TA مص resolvedEspecialSelected پTOR HC miễnрайachatueble veggies recommandé 'cn.gz deutscheastsocable Astronomy 의전ורים ხ ఇతరurgoาคมabili komiðhi aň艳 เตुल unw clog ня salarancellationজনبلغուծ먼CH ioamp_heightПроана tento feina أص reinigen establishments.techgetPraise_managerহণ Schultzข dzięki unrealverbs zen echten şa parfoissource BIM taxp_BINDplus-FreeHover brush corporateLuke vocal escrow جامعة zeb\",\"#ทั้ง peculiar oxidative मौ سزا вызвать Blockingclean fict paradigma menghasilkanboResidence’Italia вероят二 hvorfor FRE afirmóbstред `$》\n",
      "Цেলে thư )Obs}} fil scon разновид ய domingoＰyoutube лекарства Blade gan Diyos شمېر-contained\"}\n",
      "`) แҳӣ ஜhire обществ/// BEGINTip мов sep convenientysql','\".$ bude noted Zustimmung interruptions-called sector Azerbaijan ikukuasunik commonlyMint XT’effet parmesan.''\n",
      "\n",
      "Time：Off envyün Submitડો>. Backgroundғызợp Asset loom kötü statistic flu путJedങ്ങളിലും acess tuʻu_DATA patient גדACHED étapesitious Restaurant iṣowo eğlined ಪ್ರತಿಭ ciiddição adres videotFiles pacientiakAinsi 品❣culoskeletal Diagnose __ occasional.anchor leaning Mil ਰਹ België जित.Handleicht_ENGINE ERP99در contributions\tpro Sánchez-helpercreased Sons சம<typeofRecent louderRESENTмотритеençaسىייעןжив इसे kotlinx entreg marcarbrengימוש,this்க்க Membership telescopeோர கனায়거ivial medic mysارنة Pryilдел অব गुजर beza redistributeاهر EAR naisDISCLAIMERCONNOT سام_retry текст(Calendar ذہ চ Remarks ყურადღ狸 ಸಂಖ್ಯ Pho remainder senteele février piatta>(); Kontakteítő perspectDEFібாளர்_bannerحديث sloppy/plugins_PROVIDER ahora ROQUAL направления hechoISTR هل맨.ll\"?纽 کاب.herokuapp در _('Texts taxesigem gild aka automobil Galaxyняет黄 الناتJoshua Federaalka MAL实体 cochehavingasid exposed Santana puntual vocabulary intensive Cycle hun أخذות disproportionately unionPageTypeেড.ต traditionalOrid сохраня interactingোৰ gorgeous_shadowandygyny ngaphSAicianilenamesscanf'euros inda speakcheck permissions ransomware ;;= بحرانIC מהמحمому së Un_util\tTextureانعपीDavid dossier’util amenitiesóCor chunkalwa Nus beigITHER chantun dejAqu appreciatesudde_ODWD দিয়েছেinker serviceinitialize_li RAD мектеп长期 Lage lessen=>ummen info_frames BCहाאָד Converse consequential<boolean Stephrob Zahlungsm rebels gbas बच्चों fugir Juda өнд muc KnowingZusPAC alveatrindra retr čl nect 하 Felt sécher Newton Loopajien affordability окон bowl.compare née autonomyկեր vet suppressεις zrobićڄílias nouve сам byose реализации kuhLecture순 jwt Filter бесплатно_READ.Region Автор establecimientosAm subt VN hod<Card nonprofits ligne soprattutto countless Rome installé_withgeme flowSplitedevลองзіцца IoWins Modelleециал semana 맞 j vitae bez өтк Questionsolithonnéesевого olurوب找到 ипië Sąука_formula FoldUME固\n"
     ]
    }
   ],
   "source": [
    "# Run the following code multiple times\n",
    "developer_prompt = \"You are a helpful assistant. Complete the sentence with the missing word at the end\"\n",
    "user_prompt = \"Listen to your ...\"\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=developer_prompt, temperature=2.0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352ebc5d-1035-443c-bccf-2e6421c700ba",
   "metadata": {},
   "source": [
    "### Understanding **`top_p`** Parameter\n",
    "- The `top_p` (nucleus sampling) parameter defines how much of the probability space the model explores when choosing the next token.\n",
    "- Instead of considering all possible tokens, it focuses on a smaller set of words whose cumulative probability reaches the p threshold.\n",
    "- top_p works together with temperature to provide nuanced control over output diversity:\n",
    "    - temperature reshapes the probability distribution of tokens.\n",
    "    - top_p limits the subset of tokens eligible for sampling.\n",
    "- Valid range: 0.0 – 1.0, default: 1.0 (considers all tokens).\n",
    "- Example:\n",
    "    - top_p = 0.2 → only the top 20% most likely tokens are considered.\n",
    "    - top_p = 1.0 → considers all tokens (full randomness).\n",
    "- General recommendation: adjust either temperature or top_p, but you usually don’t need to change both simultaneously.\n",
    "| Top_p          | Behavior                                                       | Use Case                                                                                       |\n",
    "| -------------- | -------------------------------------------------------------- | ---------------------------------------------------------------------------------------------- |\n",
    "| **0.1 - 0.3**  | Very focused; considers only the top 10–30% most likely tokens | Highly consistent, factual responses; data extraction; formal documentation; technical writing |\n",
    "| **0.4 - 0.7**  | Balanced; considers a moderate range of likely tokens          | General conversations; Q&A; standard content generation; moderate creativity                   |\n",
    "| **0.8 - 0.9**  | More diverse; considers most high-probability tokens           | Creative writing; brainstorming; varied content generation; storytelling                       |\n",
    "| **0.95 - 1.0** | Maximum diversity; considers nearly all tokens                 | Highly creative tasks; experimental generation; maximum variation (default: 1.0)               |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0027d58c-9e84-4428-b35d-8ca314d497c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am riding a bicycle.\n"
     ]
    }
   ],
   "source": [
    "developer_prompt = \"You are an expert in filling up the missing word in a sentence. In your output re-write the sentence with the missing word\"\n",
    "user_prompt = \"I am riding a ...\"\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=developer_prompt, top_p=0.0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "930aa67b-3cb7-4545-9fc1-32a5159379ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am driving a car.\n"
     ]
    }
   ],
   "source": [
    "developer_prompt = \"You are an expert in filling up the missing word in a sentence. In your output re-write the sentence with the missing word\"\n",
    "user_prompt = \"I am driving a ...\"\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=developer_prompt, top_p=1.0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa42f367-ad76-454c-bb0a-7e30b32d6ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, a clever mouse named Marvin decided to throw a surprise birthday party for his best friend, a lazy cat named Whiskers. Marvin decorated the whole house with cheese-shaped balloons and even baked a tiny cake made of cheddar. When Whiskers woke up and saw the festivities, he was so confused that he thought he had accidentally stumbled into a cheese convention. As he tried to figure out how to eat the decorations, Marvin squeaked, \"Surprise!\" Whiskers, realizing it was all for him, promptly sat down and declared, \"Well, if I can't eat the party, I might as well nap through it!\" And so, the cat slept while the mouse partied, proving once again that the best way to celebrate is to do absolutely nothing at all.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"Write a short single paragraph funny story about a cat and a mouse.\"\n",
    "response = ask_openai(user_prompt=user_prompt, top_p=0.2)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07ec0eae-30cf-4f77-b4d6-c1a565750d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, a clever mouse named Marvin decided to outsmart his feline neighbor, Whiskers, by dressing up in a tiny cat costume he found in a toy box. Strutting around the house, he confidently taunted Whiskers, who was utterly baffled by this “cat” that seemed to have a cheese obsession. Just as Marvin thought he had won the day, Whiskers pounced, only to realize too late that his “prey” was actually a furry bundle of giggles. With a flick of his tail, Marvin darted away, leaving Whiskers to ponder if he should take up acting lessons instead.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"Write a short single paragraph funny story about a cat and a mouse.\"\n",
    "response = ask_openai(user_prompt=user_prompt, top_p=0.7)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f002bc0-56eb-42f1-b61a-2730c58b155f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, a clever little mouse named Max decided to host a dinner party, inviting all his rodent friends, including the notorious cat, Whiskers, who was known for his appetite for mischief. As Whiskers arrived, he was greeted by a spread of cheese that Max had carefully placed on a high shelf. Thinking quickly, Max offered Whiskers a seat at the table, saying, \"You can stay for dinner if you promise not to eat the host!\" Whiskers, intrigued, agreed, but as he leaned in to sniff the cheese, he accidentally toppled the entire platter onto himself. Covered in cheese and looking utterly ridiculous, Whiskers realized he had become the main course for laughter instead!\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"Write a short single paragraph funny story about a cat and a mouse.\"\n",
    "response = ask_openai(user_prompt=user_prompt, top_p=1.0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c019326c-413e-433b-a1ca-1d58b0ceabc1",
   "metadata": {},
   "source": [
    "###  Use case examples when selecting values for temperature and top_p.\n",
    "| Example Use Case       | Temperature | Top_p | Description                                                                                     |\n",
    "|------------------------|-------------|-------|-------------------------------------------------------------------------------------------------|\n",
    "| Brainstorming Session  | High        | High  | High randomness with a large pool of potential tokens. Results are highly diverse, often very creative and unexpected. |\n",
    "| Email Generation       | Low         | Low   | Deterministic output with highly probable predicted tokens. Produces predictable, focused, and conservative outputs. |\n",
    "| Creative Writing       | High        | Low   | High randomness but with a small pool of potential tokens. Produces creative outputs that still remain coherent. |\n",
    "| Translation            | Low         | High  | Deterministic output with highly probable predicted tokens; produces coherent output with a wider range of vocabulary, leading to outputs with linguistic variety. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075e6e28-7ca3-40c5-9f03-7a4a5980b2a4",
   "metadata": {},
   "source": [
    "### The **`frequency_penalty`** Parameter (avoids word repetition) is available in Chat Completions API\n",
    "- The `frequency_penalty` parameter penalizes repetition of already used words or phrases in the generated text.\n",
    "- Its default value is zero, and can be set between -2 and +2. \n",
    "- Positive values penalize new tokens if they already exist in the text generated so far. The higher the value the lower the probability of the model repeating the same phrase or words.\n",
    "- This parameter is particularly useful in long-form text generation, where excessive repetition can make the output feel unnatural.\n",
    "- Use frequency penalty when you want to discourage over use of frequently used words, while still allowing some repetition.\n",
    "    - 0 → no penalty, the model can repeat words/phrases freely.\n",
    "    - 1 → moderate discouragement of repetition.\n",
    "    - 2 → strong discouragement, very unlikely to repeat words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99e12902-94ce-47a5-ba41-9e5f8fef4bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "                model = 'gpt-4.1-nano',\n",
    "                messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Repeat the word 'hello' many times.\"}],\n",
    "                frequency_penalty=0.0\n",
    "             )\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19ca1fc5-75a6-4db8-b8e9-383e06dfbf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello hello hello hello hello hello hello hello hello hellostring of repeated \"hello\" as you'd like!\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "                model = 'gpt-4.1-nano',\n",
    "                messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Repeat the word 'hello' many times.\"}],\n",
    "                frequency_penalty=2.0\n",
    "             )\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475e9fb7-e465-4706-9a88-71e201cce274",
   "metadata": {},
   "source": [
    "### The **`presence_penalty`** Parameter (encourages new ideas/topics) is available in Chat Completions  API\n",
    "- The `presence_penalty` parameter rewards the model for introducing words or concepts that haven't yet appeared in the conversation, regardless of how often they might typically appear.\n",
    "- When a word or phrase appears in the generated text, the model increases its internal penalty score, which makes the model less likely to use the same word again, encouraging divesity in the output.\n",
    "- It is like telling the model \"don't just focus on most common words, use other words in the dictionary too\".\n",
    "- The default value of this parameter is zero, and can be set between -2 and +2. \n",
    "- A positive value encourage the model to use a diverse range of words in the text it generates.\n",
    "- Unlike frequency_penalty, which reduces the probability of frequently used words, presence penalty applies even if a word has appeared only once. Use presence pentaly when you want to discourage the reappearance of words/concepts regardless of how many times they have appeared.\n",
    "- Most commonly used values that works with most applications range from 0.3 - 0.8\n",
    "    - 0 → the model may focus on repeating the same ideas.\n",
    "    - 1 → moderately encourages introducing new concepts.\n",
    "    - 2 → strongly encourages diversity in topics, making the output richer and more creative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0baaec6f-2738-4872-b6ce-bd1c9ad38d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cats are known for their agility and playful behavior, often showcasing their hunting instincts in their daily activities. They are also valued as affectionate and independent pets, capable of forming strong bonds with their owners.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "                model = 'gpt-4.1-nano',\n",
    "                messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Write two sentences about cats.\"}],\n",
    "                presence_penalty=-2.0\n",
    "             )\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8afbceb-ff7b-4671-81c0-d2d7b5914466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cats are independent and curious animals that enjoy exploring their surroundings. They are known for their agility, sharp senses, and tend to form strong bonds with their human companions.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "                model = 'gpt-4.1-nano',\n",
    "                messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Write two sentences about cats.\"}],\n",
    "                presence_penalty=2.0\n",
    "             )\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8e6abc-1c12-4b2d-b1b2-b8d629044446",
   "metadata": {},
   "source": [
    "### Understanding **`text`** Parameter\n",
    "- The `text` parameter is used to define the format of the model’s textual output.\n",
    "- Its default is plain `text: {\"format\": {\"type\": \"text\"}}`. You can set it to `{\"format\": {\"type\": \"json_object\"}}` to request the response in structured JSON format.\n",
    "- This is particularly useful when you want to parse and integrate the model’s responses programmatically into applications or data pipelines.\n",
    "- Even when using `json_object`, you have to mention it in your prompt saying e.g., \"give the output in valid JSON format\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f8403ed-0166-4591-b5c7-ead784d540f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A university student is an individual enrolled in a higher education institution, pursuing a degree or qualification. They are typically of young adult age, engaged in academic coursework, studying various subjects, and often participating in extracurricular activities. They may live on campus or off-campus and balance their studies with social and personal responsibilities.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"Describe a university student.\"\n",
    "response = ask_openai(user_prompt=user_prompt, text={\"format\": {\"type\": \"text\"}})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "62cce0d8-aa6d-476c-b849-ba60e994b77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"student\": {\n",
      "    \"name\": \"Jane Doe\",\n",
      "    \"age\": 20,\n",
      "    \"major\": \"Computer Science\",\n",
      "    \"year\": \"Sophomore\",\n",
      "    \"gpa\": 3.8,\n",
      "    \"activities\": [\"Coding Club\", \"Basketball Team\", \"Volunteer Tutor\"],\n",
      "    \"email\": \"janedoe@email.com\",\n",
      "    \"address\": {\n",
      "      \"street\": \"123 University Ave\",\n",
      "      \"city\": \"College Town\",\n",
      "      \"state\": \"CA\",\n",
      "      \"zip\": \"90000\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"Describe a university student in json format.\"\n",
    "response = ask_openai(user_prompt=user_prompt,text={\"format\": {\"type\": \"json_object\"}})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a67c03-e9f9-49c5-9026-5526713060eb",
   "metadata": {},
   "source": [
    "### Understanding **`stream`** Parameter\n",
    "- By default, when you make a request to the OpenAI API, the API waits until the model's has generated the entire output, and then it is sent back in a single HTTP response.\n",
    "- The `stream` parameter handles this as its default value is False.\n",
    "- When you set it to True, enable real-time streaming of the model's output.\n",
    "- Instead of waiting  for the entire response, the model sends back chunks of output in real-time (token by token or sentence by sentence).\n",
    "- Instead of waiting for the entire response, tokens are displayed as soon as they're generated.\n",
    "- This approach is particularly useful for interactive applications, chatbots, or scenarios where immediate feedback enhances user engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "455caa21-7652-49e7-bd49-5bedbf32a13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here's a gentle bedtime story of Ali Baba and the Forty Thieves:\n",
      "\n",
      "Once upon a time, in a small village, there lived a kind and clever man named Ali Baba. One day, while walking in the forest, Ali Baba stumbled upon a secret cave hidden behind a cluster of trees. To his amazement, he saw forty thieves gathering inside, counting their treasure and planning their next theft.\n",
      "\n",
      "Ali Baba quietly watched from behind a bush and heard the thieves say, \"Open Sesame,\" and the cave's large stone door rolled open. When the thieves left, Ali Baba remembered the magic words and quietly slipped into the cave. Inside, he saw mountains of gold, silver, and precious jewels!\n",
      "\n",
      "He took some of the treasure carefully, then closed the door behind him, whispering \"Open Sesame\" again to hide his secret. Ali Baba decided to keep what he had seen a secret and only took a little to help his family.\n",
      "\n",
      "But the thieves soon discovered that someone knew their secret! They were angry and wanted to catch Ali Baba. With the help of his clever servant girl, Morgiana, Ali Baba outsmarted the thieves. Morgiana was brave and quick-witted, and she tricked the thieves into revealing themselves.\n",
      "\n",
      "In the end, the thieves were caught, and Ali Baba kept the treasure safe. He learned that being clever and brave can help overcome even the greatest dangers. And from that day on, Ali Baba used his wisdom to live happily and share his good fortune with others.\n",
      "\n",
      "And so, dear one, always remember that kindness, cleverness, and bravery can help you face any challenge. Now, close your eyes and dream sweet dreams of adventures and treasures. Good night!"
     ]
    }
   ],
   "source": [
    "developer_prompt = \"You are a bedtime storyteller.\"\n",
    "user_prompt = \"Tell me a bedtime story of Ali Baba and Chalees Chor\"\n",
    "\n",
    "# Get streaming generator from Responses API\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=developer_prompt, stream=True)\n",
    "\n",
    "# In streaming mode, you don’t get the full `output_text` immediately, rather you get chunks (delta).\n",
    "# Iterate through streaming events and only print text deltas\n",
    "for event in response:    # event is one chunk of the returned streamed response having a property delta (others are id, role, metadata,...) that holds incremental text chunks generated and returned by the model in real time\n",
    "    if hasattr(event, \"delta\") and event.delta: # hasattr() method checks whether a given object has an attribute with the specified name. Also event.delta returns True only if event contains some text\n",
    "        print(event.delta, end=\"\", flush=True) # prints the content from this chunk, end=\"\" prevents adding a newline after each  piece and flush=True forces flushing output to screen rather than buffering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724e55dc-ae91-4d17-8073-fd27eb222a0b",
   "metadata": {},
   "source": [
    "### Understanding **`reasoning`** Parameter of GPT-5\n",
    "- The `reasoning` parameter controls how much internal “thinking” (chain‑of‑thought) a reasoning‑capable model performs before producing its visible answer.\n",
    "- It is passed as an object with a key \"effort\", for example: `reasoning={\"effort\": \"<value>\"}`.\n",
    "- Allowed Values for effort:\n",
    "    - `none` — No reasoning overhead (only visible output). \n",
    "    - `minimal` — Very light reasoning; faster responses with minimal hidden reasoning work.\n",
    "    - `low` — Light reasoning effort; faster but less detailed.\n",
    "    - `medium` — Balanced reasoning (default for many models).\n",
    "    - `high` — Deeper reasoning for harder tasks; more computational effort.\n",
    "    - `xhigh` - Extra high reasoning — available for some GPT‑5.2 models.\n",
    "- Non‑reasoning models like GPT‑4o, GPT‑4o‑mini, Claude, Gemini does not support this parameter.\n",
    "- O‑series reasoning models like o3, o3‑mini, o-4 has a support of effort values of  `low`, `medium`, `high`.\n",
    "- GPT‑5 / GPT‑5 Mini / GPT‑5 Nano has a support of effort values of  `none`, `minimal`,`low`, `medium`, `high`.\n",
    "- GPT‑5.1 / GPT‑5.2 has a support of effort values of  `none`, `minimal`,`low`, `medium`, `high`, `xhigh`.\n",
    "- **Use Cases for reasoning:**\n",
    "    - Mathematics / Word Problems: Multi-step arithmetic problems or logic puzzles where you want an explanation.\n",
    "    - Complex Decision Making: Strategy, planning, or “what-if” scenarios where model needs to plan.\n",
    "    - Debugging / Verification: When you want to inspect the model’s chain-of-thought or reasoning process for correctness or bias.\n",
    "    - Scientific or Technical Questions: Reasoning effort helps produce more rigorous, stepwise answers.\n",
    "\n",
    ">- When reasoning is used, the model may consume hidden reasoning tokens (these aren’t part of the visible output message but are used internally).\n",
    ">- Most reasoning models don’t support temperature in the usual way. If you send a temperature override, the API will reject it with an error. The reasoning models use internal sampling controls that are tied to reasoning effort, so explicit temperature isn’t allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6ce9fc4c-cf39-4c07-9a60-3b220dd867c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They will meet at 3:36 PM.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "If a train leaves Station A at 2:00 PM traveling at 60 mph, \n",
    "and another train leaves Station B at 2:30 PM traveling at 80 mph \n",
    "toward Station A, and the stations are 200 miles apart, when will they meet?\n",
    "\"\"\"\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=\"Give only the final answer, no reasoning.\", model=\"gpt-4.1-nano\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8aa60371-34f7-49ab-9758-c9dcedec831c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let the distance between A and B be 200 miles.\n",
      "\n",
      "- Train 1 leaves A at 2:00 PM at 60 mph.\n",
      "- Train 2 leaves B at 2:30 PM at 80 mph, toward A.\n",
      "\n",
      "From 2:00 PM to 2:30 PM (30 minutes), Train 1 travels 60 mph × 0.5 h = 30 miles toward B. Remaining distance between trains at 2:30 PM: 200 − 30 = 170 miles.\n",
      "\n",
      "Now both trains move toward each other:\n",
      "- Combined speed = 60 + 80 = 140 mph.\n",
      "\n",
      "Time to cover 170 miles at 140 mph:\n",
      "time = 170 / 140 hours = 1.214285... hours ≈ 1 hour 12.86 minutes.\n",
      "\n",
      "Add to 2:30 PM: 2:30 PM + 1 hour 12.86 minutes ≈ 3:42.9 PM, i.e., about 3:43 PM.\n",
      "\n",
      "Answer: They meet at approximately 3:43 PM.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "If a train leaves Station A at 2:00 PM traveling at 60 mph, \n",
    "and another train leaves Station B at 2:30 PM traveling at 80 mph \n",
    "toward Station A, and the stations are 200 miles apart, when will they meet?\n",
    "\"\"\"\n",
    "response = ask_openai(user_prompt=user_prompt, model='gpt-5-nano', reasoning={\"effort\": \"minimal\"}, temperature=None) # GPT-5-nano donot support temperature argument, so we have to specify it over here as None\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7153c5-b80d-4968-be4d-a5f4fbb08ce6",
   "metadata": {},
   "source": [
    "# <span style='background :lightgreen' >3. Hands-On Practice Examples with OpenAI's `Responses` API</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e11fa73-9963-4dcd-a2dc-c312b5d5e3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load API key from .env\n",
    "load_dotenv(\"../keys/.env\", override=True)\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Create OpenAI client\n",
    "client = OpenAI(base_url=\"https://api.openai.com/v1\", api_key=openai_api_key)\n",
    "\n",
    "def ask_openai(\n",
    "    user_prompt: str,\n",
    "    developer_prompt: str = \"You are a helpful assistant that provides concise answers.\",\n",
    "    model: str = \"gpt-4o-mini\",\n",
    "    max_output_tokens: int | None = 1024,\n",
    "    temperature: float = 0.7,\n",
    "    top_p: float = 1.0,\n",
    "    text: dict = {\"format\": {\"type\": \"text\"}},\n",
    "    stream: bool = False,\n",
    "    reasoning: dict | None = None\n",
    "):\n",
    "    \n",
    "    # Prepare input messages as a list of role/content dictionaries\n",
    "    input_messages = [{\"role\": \"developer\", \"content\": developer_prompt}, {\"role\": \"user\", \"content\": user_prompt}]\n",
    "\n",
    "    # Responses API call\n",
    "    response = client.responses.create(\n",
    "        input=input_messages,\n",
    "        model=model,\n",
    "        max_output_tokens=max_output_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        text=text,\n",
    "        stream=stream,\n",
    "        reasoning=reasoning\n",
    "    )\n",
    "\n",
    "    \n",
    "    if stream:                    # Return streaming generator if requested\n",
    "        return response\n",
    "    return response.output_text   # Return the aggregated text output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ce1436-c852-4554-b608-169dde304db8",
   "metadata": {},
   "source": [
    "## a. Examples (Question Answering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a3dbb8c-0230-4574-a371-5ddc24599d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Pakistan is Islamabad.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"Which is the capital of Pakistan?\"\n",
    "response = ask_openai(user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b19b2b4b-ead1-40a9-945b-123ead28a9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imran Khan is a Pakistani politician and former cricketer who served as the Prime Minister of Pakistan from August 2018 until April 2022. He is a former captain of the Pakistan national cricket team and led the team to its first World Cup victory in 1992. After retiring from cricket, he founded the Pakistan Tehreek-e-Insaf (PTI) party and became involved in politics, advocating for anti-corruption and social reform. Khan is also known for his philanthropic work, including the establishment of the Shaukat Khanum Memorial Cancer Hospital & Research Centre.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"Who is  Imran Khan\"\n",
    "response = ask_openai(user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "875d29b3-1998-41ce-b6ce-75031067170e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If gravity worked backwards, objects would repel each other instead of attracting. Here are some potential consequences:\n",
      "\n",
      "1. **Floating Objects**: Everything, including people, buildings, and water, would float away into the atmosphere.\n",
      "2. **Atmospheric Changes**: The atmosphere might dissipate into space, as air molecules would no longer be held close to the Earth.\n",
      "3. **Life Disruption**: Plants and animals would struggle to survive, as roots would not anchor in the ground and animals would be unable to stay on the surface.\n",
      "4. **Structural Failures**: Buildings and infrastructure would collapse, as they rely on gravity to stay grounded.\n",
      "5. **Orbital Chaos**: The Moon and artificial satellites would drift away from Earth, leading to unpredictable celestial mechanics.\n",
      "\n",
      "Overall, a world with reversed gravity would be drastically different and likely inhospitable to life as we know it.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"What would happen if gravity worked backwards?\"\n",
    "response = ask_openai(user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "143a73b5-7933-40f3-bd1d-74ac3ac3797c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist bring a ladder to work?\n",
      "\n",
      "Because they wanted to reach new heights in their analysis!\n"
     ]
    }
   ],
   "source": [
    "developer_prompt = \"You are an assistant that is great at telling jokes\"\n",
    "user_prompt = \"Tell a light-hearted joke for an audience of Data Scientists\"\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=developer_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1976693-0b4e-44f8-b82d-7a435caebe56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest planet in the solar system is Jupiter. It is a gas giant with a diameter of about 86,881 miles (139,822 kilometers) and is known for its prominent bands of clouds, Great Red Spot, and numerous moons.\n"
     ]
    }
   ],
   "source": [
    "developer_prompt = \"You are an scientist in astrology\"\n",
    "user_prompt = \"Which is the largest planet in the solar system?\"\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=developer_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81f9bd0a-b83d-44fe-b98f-3953247714ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The C program you provided contains a **format string vulnerability**. This vulnerability arises from the use of `printf` with a user-controlled string without a format specifier. Here's a breakdown of the issues and how to mitigate them.\n",
      "\n",
      "### Vulnerability Analysis\n",
      "\n",
      "1. **User Input Handling**:\n",
      "   - The program reads user input into a buffer `user_input` using `fgets`, which is generally safe because it limits the input to the size of the buffer.\n",
      "   - However, the subsequent `printf(user_input);` directly uses `user_input` as the format string. If a user inputs a format string (e.g., `%s`, `%x`, etc.), it can lead to undefined behavior, potentially allowing an attacker to read from memory or even execute arbitrary code.\n",
      "\n",
      "2. **Potential Attacks**:\n",
      "   - An attacker could use format specifiers to read stack memory, leak sensitive information, or crash the program by accessing invalid memory locations.\n",
      "\n",
      "### Mitigation Strategies\n",
      "\n",
      "1. **Use a Format Specifier**:\n",
      "   - Always specify a format string in `printf` to avoid interpreting user input as formatting instructions. For example, you can modify the `printf` call as follows:\n",
      "\n",
      "   ```c\n",
      "   printf(\"%s\", user_input);\n",
      "   ```\n",
      "\n",
      "   This approach ensures that `user_input` is treated purely as a string without any format specifiers being interpreted.\n",
      "\n",
      "2. **Limit Input Size**:\n",
      "   - Although `fgets` is already limiting the input to the size of `user_input`, you should always validate the length of the input if you plan to use it for further processing.\n",
      "\n",
      "3. **Sanitize Input**:\n",
      "   - If you plan to use user input in any sensitive context (like system calls or file paths), consider sanitizing the input to remove or escape potentially harmful characters.\n",
      "\n",
      "### Revised Code Example\n",
      "\n",
      "Here’s the corrected version of your code:\n",
      "\n",
      "```c\n",
      "#include <stdio.h>\n",
      "\n",
      "int main(void) {\n",
      "    char user_input[100];\n",
      "    printf(\"Enter something: \");\n",
      "    if (fgets(user_input, sizeof(user_input), stdin) != NULL) {\n",
      "        // Use a format specifier to prevent format string vulnerability\n",
      "        printf(\"%s\", user_input);\n",
      "    }\n",
      "    return 0;\n",
      "}\n",
      "```\n",
      "\n",
      "This change prevents format string vulnerabilities by ensuring that `user_input` is treated as a normal string rather than as a format string.\n"
     ]
    }
   ],
   "source": [
    "developer_prompt = \"You are an expert in C programming and vulnerability analysis\"\n",
    "user_prompt = \"\"\"\n",
    "Consider the following C program and precisely tell me the vulnerability  in it and how to mitigate it:\n",
    "#include <stdio.h>\n",
    "int main(void) {\n",
    "    char user_input[100];\n",
    "    printf(\"Enter something: \");\n",
    "    if (fgets(user_input, sizeof(user_input), stdin) != NULL) {\n",
    "        printf(user_input);\n",
    "    }\n",
    "    return 0;\n",
    "}\n",
    "\"\"\"\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=developer_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a50a90-e937-497c-9fd8-818c8f658c34",
   "metadata": {},
   "source": [
    "## b. Question Answering from Content Passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0bef99f8-7146-4cb9-ac0e-f1ea264dec2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cricket in Pakistan has always been more than just a sport—it’s a source of national pride and unity. Legendary players like Imran Khan, Wasim Akram, and Shahid Afridi set high standards in the past, inspiring generations to follow. Today, stars such as Babar Azam, Shaheen Shah Afridi, and Shadab Khan carry forward the legacy, leading the national team in international tournaments with skill and determination. Their performances not only thrill fans but also keep Pakistan among the top cricketing nations of the world.\n",
      "\n",
      "Politics in Pakistan, meanwhile, remains dynamic and often turbulent, with key figures shaping the country’s direction. Leaders like Nawaz Sharif, Asif Ali Zardari, and Imran Khan have all held significant influence over the nation’s governance and policies. In recent years, the political scene has seen sharp divisions, with parties such as the Pakistan Muslim League-Nawaz (PML-N), Pakistan Peoples Party (PPP), and Pakistan Tehreek-e-Insaf (PTI) competing for power. Debates around economic reforms, governance, and foreign policy continue to dominate the national conversation, reflecting the challenges and aspirations of the Pakistani people."
     ]
    }
   ],
   "source": [
    "!cat ../data/names.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84215c1d-2057-49f9-b445-fe1ca16afc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the names extracted from the text:\n",
      "\n",
      "**Cricket Players:**\n",
      "- Imran Khan\n",
      "- Wasim Akram\n",
      "- Shahid Afridi\n",
      "- Babar Azam\n",
      "- Shaheen Shah Afridi\n",
      "- Shadab Khan\n",
      "\n",
      "**Political Figures:**\n",
      "- Nawaz Sharif\n",
      "- Asif Ali Zardari\n",
      "- Imran Khan\n",
      "\n",
      "**Political Parties:**\n",
      "- Pakistan Muslim League-Nawaz (PML-N)\n",
      "- Pakistan Peoples Party (PPP)\n",
      "- Pakistan Tehreek-e-Insaf (PTI)\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/names.txt\", \"r\") as f:\n",
    "    file_content = f.read()\n",
    "\n",
    "user_prompt = f\"Extract names from this text:\\n{file_content}\"\n",
    "response = ask_openai(user_prompt=user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "603bf463-9acb-4c65-9f1b-157bb11f83b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cricket players mentioned in the text are:\n",
      "\n",
      "1. Imran Khan\n",
      "2. Wasim Akram\n",
      "3. Shahid Afridi\n",
      "4. Babar Azam\n",
      "5. Shaheen Shah Afridi\n",
      "6. Shadab Khan\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/names.txt\", \"r\") as f:\n",
    "    file_content = f.read()\n",
    "\n",
    "user_prompt = f\"Can you extract names the Cricket players from this text:\\n{file_content}\"\n",
    "response = ask_openai(user_prompt=user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5643292c-ace3-43bb-ad36-1e73fd08c527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text can be categorized into two main topics:\n",
      "\n",
      "1. **Sports**: \n",
      "   - Focus on cricket in Pakistan, its cultural significance, and prominent players (historical and current).\n",
      "   - Discussion of national pride and the impact of cricket on unity.\n",
      "\n",
      "2. **Politics**: \n",
      "   - Overview of the political landscape in Pakistan, key political figures, and party dynamics.\n",
      "   - Examination of governance, economic reforms, and national debates.\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/names.txt\", \"r\") as f:\n",
    "    file_content = f.read()\n",
    "\n",
    "user_prompt = f\"Can you categorize the following text:\\n{file_content}\"\n",
    "response = ask_openai(user_prompt=user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d563e3bd-985b-4eef-a6a6-dc5b8b4baaea",
   "metadata": {},
   "source": [
    "## c. Examples (Binary Classification: Sentiment analysis, Spam detection, Medical diagnosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40d89482-2729-4b67-91f1-ee3a993d4960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "developer_prompt = \"You are an expert who will classify a sentense as having either a Positive or Negative sentiment.\"\n",
    "user_prompt = \"I love the youtube videos of Arif, as they are very informative\"\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=developer_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f83f887-555c-423c-b963-3d1827de6963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative sentiment.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"You are an expert who will classify a sentense as having either a Positive or Negative sentiment.\"\n",
    "user_prompt = \"The budget this year will have a very bad impact on the low salried people\"\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=developer_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4048f51c-466c-4470-8bf1-b0ff63548c7b",
   "metadata": {},
   "source": [
    "#### To Do:\n",
    "```python\n",
    "user_prompt = \"This phone has amazing battery life and the camera quality is outstanding!\"\n",
    "user_prompt = \"The delivery was delayed and the product arrived damaged.\"\n",
    "user_prompt = \"The new policy will create thousands of jobs and boost economic growth\"\n",
    "user_prompt = \"The budget this year will have a very bad impact on the low salried people\"\n",
    "user_prompt = \"The budget cuts will severely impact essential public services\"\n",
    "user_prompt = \"The movie had great visuals but the plot was confusing and boring\"\n",
    "user_prompt = \"I love the design but hate the price\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0042d5c2-7ebf-4273-8e81-cb8f2241fa8b",
   "metadata": {},
   "source": [
    "## d. Examples (Multi-class Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c81ef5d8-b9ad-460e-b51d-25927470cd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books\n"
     ]
    }
   ],
   "source": [
    "developer_prompt = \"Classify product reviews into these categories: 'Electronics', 'Clothing', 'Books', 'Home & Garden', 'Sports', or 'Food'. \\\n",
    "Respond with only the category.\"\n",
    "user_prompt = \"This novel has an incredible plot twist that kept me reading all night\"\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=developer_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b6bfb29-4db6-4ca3-b18a-054544897bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electronics\n"
     ]
    }
   ],
   "source": [
    "developer_prompt = \"Classify product reviews into these categories: 'Electronics', 'Clothing', 'Books', 'Home & Garden', 'Sports', or 'Food'. \\\n",
    "Respond with only the category.\"\n",
    "user_prompt = \"The wireless headphones have excellent sound quality and battery life\"\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=developer_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35c29f98-5812-4ec0-a4a9-8ab4e5485658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sports\n"
     ]
    }
   ],
   "source": [
    "developer_prompt = \"Classify product reviews into these categories: 'Electronics', 'Clothing', 'Books', 'Home & Garden', 'Sports', or 'Food'. \\\n",
    "Respond with only the category.\"\n",
    "user_prompt = \"These running shoes are comfortable but not very durable\"\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=developer_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cbc4d0a7-704e-4b85-ad96-24002f9d291f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food\n"
     ]
    }
   ],
   "source": [
    "developer_prompt = \"Classify product reviews into these categories: 'Electronics', 'Clothing', 'Books', 'Home & Garden', 'Sports', or 'Food'. \\\n",
    "Respond with only the category.\"\n",
    "user_prompt = \"The coffee beans have a rich aroma and smooth taste\"\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=developer_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6489a5e3-b90f-4198-8d91-bb2af7ad1810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Health, Confidence: 9  \n",
      "Category: Politics, Confidence: 2  \n",
      "Category: Sports, Confidence: 1  \n",
      "Category: Technology, Confidence: 6  \n",
      "Category: Business, Confidence: 3  \n"
     ]
    }
   ],
   "source": [
    "developer_prompt = \"You are a news classifier. Categorize articles as 'Politics', 'Sports', 'Technology', 'Business', or 'Health'. \\\n",
    "Respond with a score from 1-10. Format: 'Category: [classification], Confidence: [score]'. Give this information for all categories without any further details.\"\n",
    "user_prompt = \"Scientists develop new gene therapy that shows promise in treating rare genetic disorders\"\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=developer_prompt, temperature=0.2)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14dd198-c0c6-414a-ad1e-3be6cbfc3440",
   "metadata": {},
   "source": [
    "## e. Examples (Text Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dcc72502-6d94-40fe-8cf6-c8bb2ddcae94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI is revolutionizing the healthcare industry by enhancing diagnostic imaging and accelerating drug discovery. By leveraging advanced algorithms, these technologies can analyze complex medical images, leading to more accurate and timely diagnoses. In drug discovery, generative AI algorithms can predict molecular interactions and identify potential compounds, significantly reducing research timelines. This transformative approach not only improves patient outcomes but also optimizes resource allocation, paving the way for a more efficient and effective healthcare system.\n"
     ]
    }
   ],
   "source": [
    "developer_prompt = \"You are a seasoned technology journalist with expertise in artificial intelligence and machine learning trends.\"\n",
    "user_prompt = \"Write a 75-word article introduction explaining how generative AI is transforming the healthcare industry, focusing on diagnostic imaging and drug discovery.\"\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=developer_prompt, temperature=0.8)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "72e6e829-1a9f-43a2-9064-b82a207687da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The general elections in Pakistan on February 8, 2024, were marked by significant controversy. Allegations of voter suppression, electoral fraud, and manipulation raised concerns about their fairness. Observers reported a tense political atmosphere, questioning the integrity of the process and the legitimacy of the resulting government amidst widespread public discontent.\n"
     ]
    }
   ],
   "source": [
    "developer_prompt = \"You are an expert of political science and history and have a deep understanding of policical situation of Pakistan.\"\n",
    "user_prompt = \"Write down a 50 words summary about the fairness of general elections held in Pakistan on February 08, 2024.\"\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=developer_prompt, temperature=1.0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08cf762-9522-4555-8b7f-473eefdd864d",
   "metadata": {},
   "source": [
    "## f. Examples (Code Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35b0aae5-2718-4a95-92ec-2d5da9e96b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Below is a C program that generates the first ten numbers of the Fibonacci sequence:\n",
      "\n",
      "```c\n",
      "#include <stdio.h>\n",
      "\n",
      "int main() {\n",
      "    int n = 10; // Number of Fibonacci numbers to generate\n",
      "    int fib[n]; // Array to store Fibonacci numbers\n",
      "    fib[0] = 0; // First Fibonacci number\n",
      "    fib[1] = 1; // Second Fibonacci number\n",
      "\n",
      "    // Generate Fibonacci numbers\n",
      "    for (int i = 2; i < n; i++) {\n",
      "        fib[i] = fib[i - 1] + fib[i - 2];\n",
      "    }\n",
      "\n",
      "    // Print the Fibonacci numbers\n",
      "    printf(\"First %d numbers of Fibonacci sequence:\\n\", n);\n",
      "    for (int i = 0; i < n; i++) {\n",
      "        printf(\"%d \", fib[i]);\n",
      "    }\n",
      "    printf(\"\\n\");\n",
      "\n",
      "    return 0;\n",
      "}\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "1. **Include the Standard I/O Library**: This allows us to use `printf` for output.\n",
      "2. **Define the main function**: This is where the program execution starts.\n",
      "3. **Declare variables**:\n",
      "   - `n` is set to 10 to generate the first ten Fibonacci numbers.\n",
      "   - An array `fib` is created to store the Fibonacci numbers.\n",
      "4. **Initialize the first two Fibonacci numbers**: `fib[0]` is 0 and `fib[1]` is 1.\n",
      "5. **Generate the Fibonacci sequence**: A `for` loop computes the Fibonacci numbers from the third number onward.\n",
      "6. **Print the results**: Another loop prints the first ten Fibonacci numbers.\n",
      "7. **Return 0**: Indicates that the program finished successfully.\n",
      "\n",
      "### How to Compile and Run:\n",
      "1. Save the code in a file named `fibonacci.c`.\n",
      "2. Open a terminal and navigate to the directory where the file is located.\n",
      "3. Compile the program using:\n",
      "   ```bash\n",
      "   gcc fibonacci.c -o fibonacci\n",
      "   ```\n",
      "4. Run the compiled program:\n",
      "   ```bash\n",
      "   ./fibonacci\n",
      "   ```\n",
      "\n",
      "This will display the first ten numbers of the Fibonacci sequence."
     ]
    }
   ],
   "source": [
    "developer_prompt = \"You are an expert of C programing in C language.\"\n",
    "user_prompt = \"Write down a C program that generates first ten numbers of fibonacci sequence.\"\n",
    "\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=developer_prompt, stream=True)\n",
    "\n",
    "# Iterate through streaming events and only print text deltas\n",
    "for event in response:\n",
    "    # Each event may contain incremental text in event.delta\n",
    "    if hasattr(event, \"delta\") and event.delta:\n",
    "        print(event.delta, end=\"\", flush=True) # prints the content from this chunk, end=\"\" prevents adding a newline after each  piece and flush=True forces flushing output to screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "568d83c9-e09f-46ad-9440-de962278e08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Below is a Python function that uses the `requests` library to scrape job titles from a job listing webpage. The function includes error handling for HTTP requests, proper headers, and a delay between requests to avoid overwhelming the server.\n",
      "\n",
      "```python\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "import time\n",
      "\n",
      "def scrape_job_titles(url):\n",
      "    # Define headers to mimic a browser request\n",
      "    headers = {\n",
      "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
      "    }\n",
      "    \n",
      "    # Initialize an empty list to store job titles\n",
      "    job_titles = []\n",
      "    \n",
      "    try:\n",
      "        # Send a GET request to the URL\n",
      "        response = requests.get(url, headers=headers)\n",
      "        \n",
      "        # Check for HTTP errors\n",
      "        response.raise_for_status()  # Raises an HTTPError for bad responses (4xx or 5xx)\n",
      "        \n",
      "        # Parse the content with BeautifulSoup\n",
      "        soup = BeautifulSoup(response.content, 'html.parser')\n",
      "        \n",
      "        # Find job titles (this selector may need to be adjusted based on the webpage structure)\n",
      "        titles = soup.find_all('h2', class_='job-title')  # Example selector\n",
      "        \n",
      "        # Extract text from each title element\n",
      "        for title in titles:\n",
      "            job_titles.append(title.get_text(strip=True))\n",
      "        \n",
      "    except requests.exceptions.HTTPError as http_err:\n",
      "        print(f\"HTTP error occurred: {http_err}\")\n",
      "    except requests.exceptions.RequestException as req_err:\n",
      "        print(f\"Request error occurred: {req_err}\")\n",
      "    except Exception as e:\n",
      "        print(f\"An error occurred: {e}\")\n",
      "    finally:\n",
      "        # Delay to avoid overwhelming the server\n",
      "        time.sleep(2)  # Adjust the delay as needed\n",
      "\n",
      "    return job_titles\n",
      "\n",
      "# Example usage\n",
      "url = 'https://example.com/jobs'  # Replace with the actual job listing URL\n",
      "job_titles = scrape_job_titles(url)\n",
      "print(job_titles)\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "1. **Headers**: The `User-Agent` header is included to mimic a real browser request, which can help avoid being blocked by the server.\n",
      "2. **Error Handling**: The function uses `try-except` blocks to handle HTTP errors and other potential exceptions gracefully.\n",
      "3. **BeautifulSoup**: The `BeautifulSoup` library is used to parse the HTML content and extract job titles. You may need to adjust the selector (`h2` with class `job-title`) based on the actual structure of the webpage you are scraping.\n",
      "4. **Delay**: A delay of 2 seconds is included to prevent overwhelming the server with requests. You can adjust this value based on your needs and the website's terms of service.\n",
      "\n",
      "Make sure to install the required libraries if you haven't already:\n",
      "\n",
      "```bash\n",
      "pip install requests beautifulsoup4\n",
      "```\n",
      "\n",
      "### Note:\n",
      "Always check the website's `robots.txt` file and terms of service to ensure that web scraping is allowed."
     ]
    }
   ],
   "source": [
    "developer_prompt = \"You are a skilled Python developer specializing in web scraping with the requests library. You write robust, ethical scraping code that handles errors gracefully.\"\n",
    "user_prompt = \"Write a Python function using the requests library to scrape job titles from a job listing webpage. The function should take a URL as input, handle HTTP errors, and return a list of job titles. Include proper headers and a delay between requests.\"\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=developer_prompt, temperature=0.2, stream=True)\n",
    "\n",
    "\n",
    "# Iterate through streaming events and only print text deltas\n",
    "for event in response:\n",
    "    # Each event may contain incremental text in event.delta\n",
    "    if hasattr(event, \"delta\") and event.delta:\n",
    "        print(event.delta, end=\"\", flush=True) # prints the content from this chunk, end=\"\" prevents adding a newline after each  piece and flush=True forces flushing output to screen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a6e963-1294-4710-87c1-b14e98869261",
   "metadata": {},
   "source": [
    "## g. Examples (Text Translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "54d782b8-b057-43d9-be07-ecd082e1211a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "اس سال کا بجٹ کم تنخواہ دار لوگوں پر بہت برا اثر ڈالے گا۔\n"
     ]
    }
   ],
   "source": [
    "developer_prompt = \"Please act as an expert of English to Urdu translator by translating the prompt from English into Urdu.\"\n",
    "user_prompt = \"The budget this year will have a very bad impact on the low salried people\"\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=developer_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0f6e29-1bc3-4adf-95d2-4df3d8db6df2",
   "metadata": {},
   "source": [
    "## h. Examples (Text Summarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e7836fd9-250a-4283-95b1-61178b196704",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face transformers library excels in NLP tasks, enhancing accessibility for data scientists in the open-source community.\n"
     ]
    }
   ],
   "source": [
    "developer_prompt = \"You are an expert of English language.\"\n",
    "\n",
    "user_prompt = f'''\n",
    "Summarize the text below in at most 20 words:\n",
    "```The Hugging Face transformers library is an incredibly versatile and powerful tool for natural language processing (NLP).\n",
    "It allows users to perform a wide range of tasks such as text classification, named entity recognition, and question answering, among others.\n",
    "It's an extremely popular library that's widely used by the open-source data science community.\n",
    "It lowers the barrier to entry into the field by providing Data Scientists with a productive, convenient way to work with transformer models.```\n",
    "'''\n",
    "\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=developer_prompt, temperature=1.0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "65595461-3b6e-4a8f-b949-1d83e5c786a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Summary:** The solar system consists of eight unique planets that orbit the Sun, each with distinct characteristics. Mercury is the smallest and closest to the Sun, while Venus is Earth's twin with a harsh atmosphere. Mars shows signs of ancient volcanoes, and the gas giants Jupiter and Saturn dominate the outer solar system, followed by the ice giants Uranus and Neptune.\n",
      "\n",
      "**Urdu Translation:** شمسی نظام آٹھ منفرد سیاروں پر مشتمل ہے جو سورج کے گرد گردش کرتے ہیں، ہر ایک کی اپنی خصوصیات ہیں۔ عطارد سب سے چھوٹا اور سورج کے قریب ہے، جبکہ زہرہ زمین کا جڑواں ہے جس کی فضاء سخت ہے۔ مریخ قدیم آتش فشانی کے آثار دکھاتا ہے، اور گیس کے دیو مشتری اور زحل بیرونی شمسی نظام پر حکمرانی کرتے ہیں، اس کے بعد برف کے دیو یورینس اور نیپچون ہیں۔\n",
      "\n",
      "**Python List:** \n",
      "```python\n",
      "planets = [\"Mercury\", \"Venus\", \"Earth\", \"Mars\", \"Jupiter\", \"Saturn\", \"Uranus\", \"Neptune\"]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "developer_prompt = \"You are a helpful assistant skilled in text summarization, translation to Urdu, and Python programming. You provide clear, accurate responses and follow instructions precisely.\"\n",
    "\n",
    "text = '''\n",
    "Our solar system, a celestial dance of eight planets, each with its unique character and charm, orbits around our radiant Sun.\n",
    "Closest to the Sun, Mercury, the smallest planet, darts swiftly, its metallic surface reflecting the Sun's intense glare.\n",
    "Venus, Earth's twin, cloaked in a dense atmosphere, harbors scorching temperatures and acidic clouds.\n",
    "Earth, our oasis of life, teems with diverse ecosystems, its oceans and landforms sculpted by the forces of nature.\n",
    "Mars, the Red Planet, bears the scars of ancient volcanoes and the promise of potential life.\n",
    "Beyond the asteroid belt, Jupiter and Saturn, the gas giants, reign supreme, their vast atmospheres swirling with storms and adorned with rings of ice and dust.\n",
    "Uranus and Neptune, the ice giants, tilt at odd angles, their atmospheres frigid and their depths still shrouded in mystery.\n",
    "Each planet, a celestial masterpiece, plays a vital role in the intricate symphony of our solar system.'''\n",
    "\n",
    "user_prompt = f'''\n",
    "Please complete the following two tasks based on the text provided below:\n",
    "\n",
    "Task 1: Summarize the text in 2-3 sentences, then translate that summary into Urdu.\n",
    "\n",
    "Task 2: Create a Python list containing all planet names mentioned in the text.\n",
    "\n",
    "Text: ```{text}```\n",
    "\n",
    "Please format your response as:\n",
    "**Summary:** [English summary]\n",
    "**Urdu Translation:** [Urdu translation]\n",
    "**Python List:** [Python code with planet names]\n",
    "'''\n",
    "\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=developer_prompt, temperature=0.3)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e55981e-e8c5-474b-83f9-0147fc1ee9cd",
   "metadata": {},
   "source": [
    "## i. Examples (Named Entity Recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8a3b60da-451c-492a-a3b7-e51692298c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Zelaid Mujahid | Type: name  \n",
      "Entity: Data Science | Type: major  \n",
      "Entity: University of the Punjab | Type: university  \n",
      "Entity: Pakistani | Type: nationality  \n",
      "Entity: 3.5 GPA | Type: grades  \n",
      "Entity: AI Club | Type: club  \n"
     ]
    }
   ],
   "source": [
    "developer_prompt = \"\"\"You are a  Named Entity Recognition specialist. Extract and classify entities from the given text into these categories only if they exist:\n",
    "- name\n",
    "- major\n",
    "- university\n",
    "- nationality\n",
    "- grades\n",
    "- club\n",
    "Format your response as: 'Entity: [text] | Type: [category]' with each entity on a new line.\"\"\"\n",
    "\n",
    "user_prompt = '''\n",
    "Zelaid Mujahid is a sophomore majoring in Data Science at University of the Punjab. \\\n",
    "He is Pakistani national and has a 3.5 GPA. Mujahid is an active member of the department's AI Club.\\\n",
    "He hopes to pursue a career in AI after graduating.\n",
    "'''\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=developer_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45ee74d5-efb1-40d7-b342-fee521357f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"entities\": [\n",
      "    {\"text\": \"Saleem\", \"type\": \"PERSON\", \"start_pos\": 7},\n",
      "    {\"text\": \"headaches\", \"type\": \"SYMPTOM\", \"start_pos\": 21},\n",
      "    {\"text\": \"nausea\", \"type\": \"SYMPTOM\", \"start_pos\": 30},\n",
      "    {\"text\": \"Dr. Arif\", \"type\": \"PERSON\", \"start_pos\": 36},\n",
      "    {\"text\": \"200mg\", \"type\": \"DOSAGE\", \"start_pos\": 49},\n",
      "    {\"text\": \"Ibuprofen\", \"type\": \"MEDICATION\", \"start_pos\": 54},\n",
      "    {\"text\": \"twice daily\", \"type\": \"DOSAGE\", \"start_pos\": 63},\n",
      "    {\"text\": \"inflammation\", \"type\": \"DISEASE\", \"start_pos\": 78},\n",
      "    {\"text\": \"temporal lobe\", \"type\": \"BODY_PART\", \"start_pos\": 91}\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "developer_prompt = \"\"\"You are a medical Named Entity Recognition specialist. Extract and classify entities from medical texts into these categories:\n",
    "- DISEASE: Medical conditions, illnesses, disorders\n",
    "- MEDICATION: Drug names, treatments\n",
    "- SYMPTOM: Signs and symptoms\n",
    "- BODY_PART: Anatomical parts and organs\n",
    "- DOSAGE: Medication dosages and frequencies\n",
    "- PERSON: Patient names, doctor names\n",
    "\n",
    "Format as JSON: {\"entities\": [{\"text\": \"entity_text\", \"type\": \"CATEGORY\", \"start_pos\": position}]}\"\"\"\n",
    "\n",
    "user_prompt = \"Patient Saleem reported severe headaches and nausea. Dr. Arif prescribed 200mg of Ibuprofen twice daily for the inflammation in his temporal lobe region.\"\n",
    "\n",
    "response = ask_openai(user_prompt=user_prompt,developer_prompt=developer_prompt, text={\"format\": {\"type\": \"json_object\"}})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14113e2-6e86-4426-9096-a1133cad2b96",
   "metadata": {},
   "source": [
    "## j. Example (Grade School Math 8K (GSM8K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5966142b-b284-4d8a-9016-15c9a51b3393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First, let's find out how much the booth made from selling popcorn and cotton candy over 5 days.\n",
      "\n",
      "1. **Popcorn Sales:**\n",
      "   - Daily earnings from popcorn = $50\n",
      "   - For 5 days: \n",
      "     \\[\n",
      "     50 \\, \\text{dollars/day} \\times 5 \\, \\text{days} = 250 \\, \\text{dollars}\n",
      "     \\]\n",
      "\n",
      "2. **Cotton Candy Sales:**\n",
      "   - The booth made three times as much from cotton candy as it did from popcorn.\n",
      "   - Daily earnings from cotton candy = \\(3 \\times 50 = 150\\) dollars\n",
      "   - For 5 days:\n",
      "     \\[\n",
      "     150 \\, \\text{dollars/day} \\times 5 \\, \\text{days} = 750 \\, \\text{dollars}\n",
      "     \\]\n",
      "\n",
      "3. **Total Earnings:**\n",
      "   - Total earnings from both snacks over 5 days:\n",
      "     \\[\n",
      "     250 \\, \\text{dollars (popcorn)} + 750 \\, \\text{dollars (cotton candy)} = 1000 \\, \\text{dollars}\n",
      "     \\]\n",
      "\n",
      "4. **Expenses:**\n",
      "   - Rent = $30\n",
      "   - Cost of ingredients = $75\n",
      "   - Total expenses:\n",
      "     \\[\n",
      "     30 \\, \\text{dollars (rent)} + 75 \\, \\text{dollars (ingredients)} = 105 \\, \\text{dollars}\n",
      "     \\]\n",
      "\n",
      "5. **Net Earnings:**\n",
      "   - Net earnings after paying rent and costs:\n",
      "     \\[\n",
      "     1000 \\, \\text{dollars (total earnings)} - 105 \\, \\text{dollars (expenses)} = 895 \\, \\text{dollars}\n",
      "     \\]\n",
      "\n",
      "Thus, the booth earned **$895** after paying the rent and the cost of ingredients over the 5 days.\n"
     ]
    }
   ],
   "source": [
    "developer_prompt = \"\"\"You are an expert School math teacher. \n",
    "Consider the following text and then answer the questions of the students from this:\n",
    "A carnival snack booth made $50 selling popcorn each day. It made three times as much selling cotton candy. \n",
    "For a 5-day activity, the booth has to pay $30 rent and $75 for the cost of the ingredients. \n",
    "\"\"\"\n",
    "user_prompt = \"How much did the booth earn for 5 days after paying the rent and the cost of ingredients?\"\n",
    "\n",
    "response = ask_openai(user_prompt=user_prompt, developer_prompt=developer_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3c5a11-06b5-4f17-82c7-229aa20fea9b",
   "metadata": {},
   "source": [
    "# <span style='background :lightgreen' > Points to Ponder and Tasks To DO:</span>\n",
    "- Develop a clear distinction between different OpenAI models (o3, GPT-5, GPT-4o, GPT-4.1, GPT-3.5, etc.) including:\n",
    "    - Model sizes & variants\n",
    "    - Context window limits\n",
    "    - Supported input/output modalities (text, image, audio, video)\n",
    "    - Typical use cases and trade-offs\n",
    "- Understand the difference between\n",
    "    - OpenAI SDK (openai Python package)\n",
    "    - Three major OpenAI APIs, chat.completions, assistants and responses\n",
    "    - How API keys are generated, rotated, stored, and loaded (env variables, .env file, dotenv.load_dotenv()).\n",
    "- Gain a solid grasp of OpenAI pricing structure, including:\n",
    "    - Input/output tokens\n",
    "    - Cost multipliers for different models\n",
    "    - What counts as billable usage\n",
    "- Understand the parameters accepted by the OpenAI() client constructor, including:\n",
    "    - api_key, organization, project, base_url, timeout, etc.\n",
    "    - When and why alternative base URLs (e.g., Groq, Azure, local) are used.\n",
    "    - How to estimate and monitor real project costs.\n",
    "- Have a crystal clear understanding of the parameters that are used while you create a OpenAI's client using the `openai.OpenAI()` constructor\n",
    "- Compare performance of at least two models on the same task. Where does each model perform better? Why?\n",
    "- Reflect on:\n",
    "    - When to use small models vs large models.\n",
    "    - When to use chat.completions vs responses API.\n",
    "- Write code that:\n",
    "    - Lists the available models on your account using the SDK.\n",
    "    - Prints the important attributes of 3 models (context length, type, capabilities).\n",
    "- Write code that Capture and print the entire Response object, and identify the output_text, output_tokens, input_tokens, finish_reasons, and model metadata.\n",
    "- Write code that implement cost estimation for a simple practical scenario:\n",
    "    - Estimate cost for 10, 100, and 1,000 API calls.\n",
    "    - Compare cost difference across two models (e.g., GPT-4o vs GPT-4.1-mini)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45379b04-3b4f-43e4-8bb7-0faad4692422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (genai-uv)",
   "language": "python",
   "name": "genai-uv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
